略称,Year,Updated Date,Paper URL,Website URL,Challenge Tag,Sub-Challeng Tag,How to Solve,Training Type,Dataset,Evaluation
ProphRL, 2025-11-25, 2025-12-1, https://arxiv.org/pdf/2511.20633, https://LogosRoboticsGroup.github.io/ProphRL,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Pretrain a unified action-conditioned world model (Prophet) on diverse robot data,BC and Predictive Modeling and RL, AgiBot;DROID;OXE;LIBERO,LIBERO;SimplerEnv-WidowX;BRIDGE
DiG-Flow, 2025-12-1, 2025-12-1, https://arxiv.org/pdf/2512.01715, https://beingbeyond.github.io/DiG-Flow,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Compute a distributional discrepancy between observation and action embeddings to guide residual feature updates for robust flow matching,Predictive Modeling,LIBERO;RoboCasa,LIBERO;RoboCasa
RAGNet, 2025-7-31, 2025-12-1, https://arxiv.org/pdf/2507.23734, https://github.com/Dexmal-AI/RAGNet, Dataset Construction and Benchmarking Standards, Evaluation and Benchmark, construct a large-scale reasoning-based affordance segmentation dataset and propose AffordanceNet for open-world grasping, -, HANDAL;OXE;EgoObjects;GraspNet, HANDAL;GraspNet Novel;3DOI;RLBench
VLA-4D, 2025-11-21, 2025-12-1, https://arxiv.org/pdf/2511.17199, -, Multi-Modal Fusion and Physical World Representation, From 2D Images to SPatial Temporal Representations, Embed 3D positions and 1D time into visual features and extend actions with temporal variables for coherent manipulation, Predictive Modeling, Scan2Cap;ScanQA;ScanRef;LIBERO, LIBERO
LatBot, 2025-11-28, 2025-12-1, https://arxiv.org/pdf/2511.23034, https://mm-robot.github.io/distill_latent_action, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Learn instruction-guided latent actions from multi-frame videos and jointly decode future frames and inter-frame actions, BC and Predictive Modeling, OXE;AgiBot;EgoDex;DROID, SIMPLER;LIBERO;Franka real-robot tasks
DeepThinkVLA, 2025-10-31, 2025-12-8, https://arxiv.org/pdf/2511.15669, https://github.com/wadeKeith/DeepThinkVLA, From Complex Instructions to Robust and Real-Time Execution, Real-Time Execution and Computing Efficiency, Use a hybrid-attention decoder with SFT then outcome-based RL to align reasoning with actions, BC and RL, LIBERO demonstrations;embodied CoT dataset, LIBERO
Mantis, 2025-11-20, 2025-12-8, https://arxiv.org/pdf/2511.16175, https://github.com/zhijie-group/Mantis, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Disentangle visual foresight from action learning using a diffusion transformer head with latent action queries and progressive multimodal training, BC and Predictive Modeling, Something-Something V2;DROID;LLaVA-Instruct and 38 multimodal datasets, LIBERO
X-VLA, 2025-10-11, 2025-12-8, https://arxiv.org/pdf/2510.10274, https://thu-air-dream.github.io/X-VLA/, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Learn embodiment-specific soft prompts to absorb cross-embodiment heterogeneity and enable scalable pretraining and efficient adaptation, BC and Predictive Modeling, AGIBOT-beta;Droid;RoboMind;Soft-FOLD, LIBERO;Simpler-WidowX;Calvin;RoboTwin-2.0;VLABench
MergeVLA, 2025-11-24, 2025-12-8, https://arxiv.org/pdf/2511.18810, https://mergevla.github.io, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Introduce sparsely activated LoRA masks and cross-attention-only action experts with a training-free task router to enable mergeable multi-skill VLA policies, BC, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robot, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robo
GigaWorld-0, 2025-11-30, 2025-12-8, https://arxiv.org/pdf/2511.19861, https://giga-world-0.github.io, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Unify video generation and 3D physics-aware reconstruction to synthesize controllable embodied interaction data, BC and Predictive Modeling and RL, AgiBotWorld;RoboMind;proprietary in-house robotic platforms, PBench Robot Set;DreamGen Bench
HiMoE-VLA, 2025-12-05, 2025-12-8, https://arxiv.org/pdf/2512.05693, https://github.com/ZhiyingDu/HiMoE-VLA, Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution;Multi-Modal Fusion and Physical World Representation, Open-World Generalization;Real-Time Execution and Computing Efficiency;Dynamic and Predictive World Models, Use a hierarchical mixture of experts with action space and heterogeneity balancing experts to enable cross domain transfer;Cache intermediate VLM key value pairs for faster inference without degrading performance;Train actions with flow matching to model multimodal action distributions, BC and Predictive Modeling, OXE;ALOHA, CALVIN;LIBERO
HiF-VLA, 2025-12-10, 2025-12-15, https://arxiv.org/pdf/2512.09928, https://hifvla.github.io, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution, From 2D Images to SPatial Temporal Representations;Real-Time Execution and Computing Efficiency, Leverage low-dimensional motion vectors for hindsight foresight and action fusion in a unified latent space;Use compact motion representations to expand temporal reasoning with negligible latency, BC and Predictive Modeling, OXE;LIBERO, LIBERO-Long;CALVIN ABC
GLaD, 2025-12-10, 2025-12-15, https://arxiv.org/pdf/2512.09619, -, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning, From 2D Images to SPatial Temporal Representations;Open-World Generalization, Distill geometric features from a frozen VGGT teacher into LLM hidden states for visual tokens to fuse 3D priors;Pretrain on Bridge then fine tune with LoRA for robust policy generalization, BC, Bridge Data, LIBERO;LIBERO-PRO
ViFailback, 2025-12-03, 2025-12-15, https://arxiv.org/pdf/2512.02787, https://x1nyuzhou.github.io/vifailback.github.io, Dataset Construction and Benchmarking Standards;From Complex Instructions to Robust and Real-Time Execution;Security Interpretability and Reliable Interaction, Evaluation and Benchmark;Error Detection and Autonomous Recovery;Interpretability and Trustworthy Interaction, Build a large real-world failure VQA dataset and benchmark for diagnosis and correction;Use a VLM to detect localize and classify failures then generate textual and visual corrective guidance;Use explicit on-frame visual symbols to provide interpretable corrective cues, -, ViFailback dataset, ViFailback-Bench Lite;ViFailback-Bench Hard
RoboWheel, 2025-12-02, 2025-12-15, https://arxiv.org/pdf/2512.02729, https://zhangyuhong01.github.io/Robowheel, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Sim-to-real Gap in Deployment, Converts human hand-object interaction videos from diverse sources into training-ready supervision via a physics-aware reconstruction pipeline;Uses a simulation-augmented data flywheel with domain randomization in Isaac Sim to enrich trajectory distributions for robust real-world transfer, BC and RL, HORA;DexYCB;OakInk, Real-World-Tasks;OakInk
BayesVLA, 2025-12-12, 2025-12-22, https://arxiv.org/pdf/2512.11218, https://xukechun.github.io/papers/BayesVLA, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Decompose policy into vision-action prior and language-conditioned likelihood to mitigate modality imbalance, BC, DROID;LIBERO, LIBERO;LIBERO-PRO
Motus, 2025-12-15, 2025-12-22, https://arxiv.org/pdf/2512.13030, https://motus-robotics.github.io/motus, Multi-Modal Fusion and Physical World Representation;Dataset Construction and Benchmarking Standards, Dynamic and Predictive World Models;Multi-Source Heterogeneous Data, Integrates video generation and action experts via Mixture-of-Transformer architecture with a UniDiffuser-style scheduler;Introduces latent actions derived from optical flow to unify large-scale heterogeneous data across embodiments, BC and Predictive Modeling, RoboTwin;LIBERO;VLAbench;AC-One Data;Agilex-Aloha-2 Data, RoboTwin;LIBERO-Long;VLAbench
VLSA-AEGIS, 2025-12-09, 2025-12-22, https://arxiv.org/pdf/2512.11891, https://vlsa-aegis.github.io/, Security Interpretability and Reliable Interaction;Dataset Construction and Benchmarking Standards, Reliability and Safety Assurance;Evaluation and Benchmark, Introduce a plug-and-play safety constraint layer formulated via control barrier functions into VLA models;Construct a comprehensive safety-critical benchmark SafeLIBERO spanning distinct manipulation scenarios with varying complexities, -, -, SafeLIBERO
OXE-AugE, 2025-12-15, 2025-12-22, https://arxiv.org/pdf/2512.13100, https://OXE-AugE.github.io/, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Open-World Generalization, Augments existing datasets with diverse robot embodiments using a scalable pipeline combining simulation rendering and learned masks;Fine-tunes generalist policies on augmented data to improve zero-shot transfer to unseen embodiments, BC, OXE;OXE-AugE;Bridge Data, Robosuite;Bridge Data
DexGrasp-VLA,2025-12-13, 2025-12-22,https://arxiv.org/pdf/2511.00139,https://dexvla-seed.github.io/dex-vla, Dataset Construction and Benchmarking Standards;Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning,Multi-Source Heterogeneous Data;The GAP between Semantics Perception and Physical Interaction;Continual Learning and Incremental Skill Acquisition,Propose a Shared Autonomy framework that partitions control along macro-micro motion domains for efficient data collection;Develop an Arm-Hand Feature Enhancement module to explicitly capture distinct latent features of arm and hand movements;Implement a Corrective Human-in-the-loop Teleoperation system to enable continuous policy improvement via failure recovery,BC and Predictive Modeling,LSTM Pretraining Dataset;DexGrasp-VLA Hand Policy Dataset;End-to-End Arm-Hand VLA Dataset;Corrective Intervention Datasets,Real-world-Tasks;Long-horizon manipulation tasks;Industrial peg-in-hole assembly
VL-JEPA, 2025-12-11, 2025-12-22,https://arxiv.org/pdf/2512.10942,-,Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution,Dynamic and Predictive World Models;Real-Time Execution and Computing Efficiency,Predict continuous embeddings of target texts in an abstract representation space using a joint embedding predictive architecture;Enable selective decoding by invoking the text decoder only when significant semantic changes are detected in the predicted embedding stream,Predictive Modeling,Datacomp;YFCC-100M;Ego4D;HowTo100M;PLM-Image-Auto;PLM-Video-Auto,Something-Something V2;EgoExo4D;Kinetics-400;MSR-VTT;ActivityNet;YouCook2;GQA;TallyQA;POPE;WorldPrediction-WM
Human to Robot, 2025-12-16, 2025-12-22, https://www.physicalintelligence.company/download/human_to_robot.pdf, https://www.physicalintelligence.company/research/human_to_robot, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Co-train human videos as an additional embodiment with robot data using unified trajectory and sub-task prediction objectives, BC and Predictive Modeling, Human Video Data;Robot Teleoperation Data, Bussing;Spice;Dresser;Sort Eggs
GR00T N1, 2025-03-28, 2025-12-22, https://arxiv.org/pdf/2503.14734, https://research.nvidia.com/labs/gear/gr00t-n1_6/, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Open-World Generalization, Structure training corpora as a data pyramid unifying human videos synthetic data and real robot trajectories using latent and pseudo actions;Employ a dual-system architecture integrating a vision-language backbone with a flow-matching diffusion policy for cross-embodiment control, BC, GR00T N1 Humanoid Pre-Training Dataset;OXE;AgiBot-Alpha;RoboCasa;DexMimicGen;Ego4D;Ego-Exo4D;Assembly-101;EPIC-KITCHENS;HOI4D;HoloAssist;RH20T-Human, RoboCasa;DexMimicGen;GR-1 Tabletop;GR-1 Humanoid Real-World Tasks
WholeBodyVLA,2025-12-15,2025-12-22, https://arxiv.org/pdf/2512.11047,https://opendrivelab.com/WholeBodyVLA,Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution,Open-World Generalization;Real-Time Execution and Computing Efficiency,Train separate locomotion and manipulation latent action models on human videos to supervise VLA training;Employ a discrete command interface with two-stage curriculum RL policy for precise execution,BC and Predictive Modeling and RL,Human egocentric videos;Agibot World;Collected teleoperation trajectories,Real-World Tasks
VideoVLA, 2025-12-07,2025-12-22,  https://arxiv.org/pdf/2512.06963, https://videovla-nips2025.github.io/, Generalization and Adaptation for Continuous Learning;Multi-Modal Fusion and Physical World Representation, Open-World Generalization;Dynamic and Predictive World Models, Leverage pre-trained video generation models and a dual-prediction strategy to transfer physical knowledge to robotic manipulation;Jointly denoise video latents and action vectors within a unified multi-modal diffusion transformer architecture, BC and Predictive Modeling, OXE, SIMPLER
MoE-DP, 2025-11-07, 2025-12-22, https://arxiv.org/pdf/2511.05007, https://moe-dp-website.github.io/MoE-DP-Website/, From Complex Instructions to Robust and Real-Time Execution;Security Interpretability and Reliable Interaction, Hierarchical Planning and Task Decomposition;Error Detection and Autonomous Recovery;Interpretability and Trustworthy Interaction, Integrate a Mixture of Experts layer to decompose long-horizon tasks into specialized skills within the diffusion policy;Leverage dynamic expert routing to detect failures and reactivate appropriate experts for subtask retries;Apply auxiliary load balancing and entropy losses to enforce distinct mappings between experts and semantic task phases, BC, Self-built Data, Custom MimicGen-inspired suite;Real-world manipulation suite
MiVLA,2025-12-17,2025-12-22, https://arxiv.org/pdf/2512.15411,-,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Utilizes kinematic rules with left/right hand coordinate systems for bidirectional alignment between human and robot action spaces,BC and Predictive Modeling,RoboTwin;Human Videos,RoboTwin-2.0
EVOLVE-VLA, 2025-12-16, 2025-12-22, https://arxiv.org/pdf/2512.14666, https://showlab.github.io/EVOLVE-VLA, Generalization and Adaptation for Continuous Learning, Online Interaction and Reinforcement Learning, Introduce accumulative progress estimation mechanism and progressive horizon extension strategy to tame noisy reward signals for test-time training, BC and RL, LIBERO, LIBERO
ManualVLA, 2025-12-01, 2025-12-22, https://arxiv.org/pdf/2512.02013, https://sites.google.com/view/maunalvla, From Complex Instructions to Robust and Real-Time Execution;Generalization and Adaptation for Continuous Learning, Hierarchical Planning and Task Decomposition;Sim-to-real Gap in Deployment, Design a unified Mixture-of-Transformers framework that selectively activates planning and action experts for coherent manual generation and execution;Construct a high-fidelity digital twin toolkit using 3D Gaussian Splatting to synthesize large-scale training data, BC and Predictive Modeling, OXE;DROID;RoboMind, RLBench
PolaRiS, 2025-12-18, 2025-12-22, https://arxiv.org/pdf/2512.16881, https://polaris-evals.github.io, Dataset Construction and Benchmarking Standards, Evaluation and Benchmark, Utilizes neural reconstruction methods to turn video scans into interactive simulation environments and develops a co-training recipe to bridge real-to-sim gaps, BC, DROID;PolaRiS Simulation Dataset;LIBERO, PolaRiS;RoboArena;LIBERO
ISS,2025-12-17,2025-12-22,https://arxiv.org/pdf/2512.15020, -, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution,Dynamic and Predictive World Models;Real-Time Execution and Computing Efficiency,Introduces an implicit scene supervision module that predicts future point cloud features to enforce long-term geometric consistency;Uses a streamlined DiT architecture with sparse point cloud encoding to improve inference speed and training efficiency,BC and Predictive Modeling,Adroit;MetaWorld,Adroit;MetaWorld
GeoPredict, 2025-12-18, 2025-12-22, https://arxiv.org/pdf/2512.16811, https://jingjingqian75.github.io/GeoPredict-Page/, Multi-Modal Fusion and Physical World Representation, From 2D Images to SPatial Temporal Representations;Dynamic and Predictive World Models, Constructs a predictive 3D Gaussian geometry module to forecast workspace geometry with track guided refinement along future keypoint trajectories;Augments a continuous action policy with predictive kinematic priors that encode motion history and predict multi step 3D keypoint trajectories, BC and Predictive Modeling, RoboCasa;LIBERO, RoboCasa;LIBERO
AFI, 2025-12-08, 2025-12-22, https://arxiv.org/pdf/2512.07472, -, Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution, Open-World Generalization;Error Detection and Autonomous Recovery, Employ 3D Spatial Affordance Fields to guide VLA behavior in out-of-distribution scenarios;Detect memory traps using proprioception and execute affordance-guided rollback for recovery, BC, Self-built Data;LIBERO, Real-world manipulation tasks;LIBERO-PRO
AdaWorld, 2025-06-02, 2025-12-22, https://arxiv.org/pdf/2503.18938, https://adaptable-world-model.github.io, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning, Dynamic and Predictive World Models;Open-World Generalization, Develops an autoregressive world model conditioned on latent actions extracted from videos in a self-supervised manner;Enables efficient adaptation and action transfer to novel environments by initializing the control interface with learned latent actions, Predictive Modeling, Gym Retro;Procgen;OXEt;Ego4D;Something-Something V2;MiraData, LIBERO;Something-Something V2;Habitat;Minecraft;DMLab;nuScenes;Procgen;VP2
PhysBrain, 2025-12-19, 2025-12-22, https://arxiv.org/pdf/2512.16793, https://zgc-embodyai.github.io/PhysBrain/, Dataset Construction and Benchmarking Standards;Multi-Modal Fusion and Physical World Representation, Multi-Source Heterogeneous Data;The GAP between Semantics Perception and Physical Interaction, Transform first-person videos into multi-level schema-driven VQA supervision with enforced evidence grounding and temporal consistency to construct the E2E-3M dataset;Train an egocentric-aware embodied brain on the E2E-3M dataset to bridge vision language models with physical intelligence and enable sample-efficient VLA fine-tuning, BC and Predictive Modeling, Ego4D;BuildAI;EgoDex;FineVision;Bridge;Fractal, EgoThink;SimplerEnv