略称,Year,Updated Date,Paper URL,Website URL,Challenge Tag,Sub-Challeng Tag,How to Solve,Training Type,Dataset,Evaluation
ProphRL, 2025-11-25, 2025-12-1, https://arxiv.org/pdf/2511.20633, https://LogosRoboticsGroup.github.io/ProphRL,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Pretrain a unified action-conditioned world model (Prophet) on diverse robot data,BC and Predictive Modeling and RL, AgiBot;DROID;OXE;LIBERO,LIBERO;SimplerEnv-WidowX;BRIDGE
DiG-Flow, 2025-12-1, 2025-12-1, https://arxiv.org/pdf/2512.01715, https://beingbeyond.github.io/DiG-Flow,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Compute a distributional discrepancy between observation and action embeddings to guide residual feature updates for robust flow matching,Predictive Modeling,LIBERO;RoboCasa,LIBERO;RoboCasa
RAGNet, 2025-7-31, 2025-12-1, https://arxiv.org/pdf/2507.23734, https://github.com/Dexmal-AI/RAGNet, Dataset Construction and Benchmarking Standards, Evaluation and Benchmark, construct a large-scale reasoning-based affordance segmentation dataset and propose AffordanceNet for open-world grasping, -, HANDAL;OXE;EgoObjects;GraspNet, HANDAL;GraspNet Novel;3DOI;RLBench
VLA-4D, 2025-11-21, 2025-12-1, https://arxiv.org/pdf/2511.17199, -, Multi-Modal Fusion and Physical World Representation, From 2D Images to SPatial Temporal Representations, Embed 3D positions and 1D time into visual features and extend actions with temporal variables for coherent manipulation, Predictive Modeling, Scan2Cap;ScanQA;ScanRef;LIBERO, LIBERO
LatBot, 2025-11-28, 2025-12-1, https://arxiv.org/pdf/2511.23034, https://mm-robot.github.io/distill_latent_action, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Learn instruction-guided latent actions from multi-frame videos and jointly decode future frames and inter-frame actions, BC and Predictive Modeling, OXE;AgiBot;EgoDex;DROID, SIMPLER;LIBERO;Franka real-robot tasks
DeepThinkVLA, 2025-10-31, 2025-12-8, https://arxiv.org/pdf/2511.15669, https://github.com/wadeKeith/DeepThinkVLA, From Complex Instructions to Robust and Real-Time Execution, Real-Time Execution and Computing Efficiency, Use a hybrid-attention decoder with SFT then outcome-based RL to align reasoning with actions, BC and RL, LIBERO demonstrations;embodied CoT dataset, LIBERO
Mantis, 2025-11-20, 2025-12-8, https://arxiv.org/pdf/2511.16175, https://github.com/zhijie-group/Mantis, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Disentangle visual foresight from action learning using a diffusion transformer head with latent action queries and progressive multimodal training, BC and Predictive Modeling, Something-Something V2;DROID;LLaVA-Instruct and 38 multimodal datasets, LIBERO
X-VLA, 2025-10-11, 2025-12-8, https://arxiv.org/pdf/2510.10274, https://thu-air-dream.github.io/X-VLA/, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Learn embodiment-specific soft prompts to absorb cross-embodiment heterogeneity and enable scalable pretraining and efficient adaptation, BC and Predictive Modeling, AGIBOT-beta;Droid;RoboMind;Soft-FOLD, LIBERO;Simpler-WidowX;Calvin;RoboTwin-2.0;VLABench
MergeVLA, 2025-11-24, 2025-12-8, https://arxiv.org/pdf/2511.18810, https://mergevla.github.io, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Introduce sparsely activated LoRA masks and cross-attention-only action experts with a training-free task router to enable mergeable multi-skill VLA policies, BC, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robot, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robo
GigaWorld-0, 2025-11-30, 2025-12-8, https://arxiv.org/pdf/2511.19861, https://giga-world-0.github.io, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Unify video generation and 3D physics-aware reconstruction to synthesize controllable embodied interaction data, BC and Predictive Modeling and RL, AgiBotWorld;RoboMind;proprietary in-house robotic platforms, PBench Robot Set;DreamGen Bench
HiMoE-VLA, 2025-12-05, 2025-12-8, https://arxiv.org/pdf/2512.05693, https://github.com/ZhiyingDu/HiMoE-VLA, Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution;Multi-Modal Fusion and Physical World Representation, Open-World Generalization;Real-Time Execution and Computing Efficiency;Dynamic and Predictive World Models, Use a hierarchical mixture of experts with action space and heterogeneity balancing experts to enable cross domain transfer;Cache intermediate VLM key value pairs for faster inference without degrading performance;Train actions with flow matching to model multimodal action distributions, BC and Predictive Modeling, OXE;ALOHA, CALVIN;LIBERO
HiF-VLA, 2025-12-10, 2025-12-15, https://arxiv.org/pdf/2512.09928, https://hifvla.github.io, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution, From 2D Images to SPatial Temporal Representations;Real-Time Execution and Computing Efficiency, Leverage low-dimensional motion vectors for hindsight foresight and action fusion in a unified latent space;Use compact motion representations to expand temporal reasoning with negligible latency, BC and Predictive Modeling, OXE;LIBERO, LIBERO-Long;CALVIN ABC
GLaD, 2025-12-10, 2025-12-15, https://arxiv.org/pdf/2512.09619, -, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning, From 2D Images to SPatial Temporal Representations;Open-World Generalization, Distill geometric features from a frozen VGGT teacher into LLM hidden states for visual tokens to fuse 3D priors;Pretrain on Bridge then fine tune with LoRA for robust policy generalization, BC, Bridge Data, LIBERO;LIBERO-PRO
ViFailback, 2025-12-03, 2025-12-15, https://arxiv.org/pdf/2512.02787, https://x1nyuzhou.github.io/vifailback.github.io, Dataset Construction and Benchmarking Standards;From Complex Instructions to Robust and Real-Time Execution;Security Interpretability and Reliable Interaction, Evaluation and Benchmark;Error Detection and Autonomous Recovery;Interpretability and Trustworthy Interaction, Build a large real-world failure VQA dataset and benchmark for diagnosis and correction;Use a VLM to detect localize and classify failures then generate textual and visual corrective guidance;Use explicit on-frame visual symbols to provide interpretable corrective cues, -, ViFailback dataset, ViFailback-Bench Lite;ViFailback-Bench Hard
RoboWheel, 2025-12-02, 2025-12-15, https://arxiv.org/pdf/2512.02729, https://zhangyuhong01.github.io/Robowheel, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Sim-to-real Gap in Deployment, Converts human hand-object interaction videos from diverse sources into training-ready supervision via a physics-aware reconstruction pipeline;Uses a simulation-augmented data flywheel with domain randomization in Isaac Sim to enrich trajectory distributions for robust real-world transfer, BC and RL, HORA;DexYCB;OakInk, Real-World-Tasks;OakInk