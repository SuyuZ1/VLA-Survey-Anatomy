略称,Year,Updated Date,Paper URL,Website URL,Challenge Tag,Sub-Challeng Tag,How to Solve,Training Type,Dataset,Evaluation
ProphRL, 2025-11-25, 2025-12-1, https://arxiv.org/pdf/2511.20633, https://LogosRoboticsGroup.github.io/ProphRL,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Pretrain a unified action-conditioned world model (Prophet) on diverse robot data,BC and Predictive Modeling and RL, AgiBot;DROID;OXE;LIBERO,LIBERO;SimplerEnv-WidowX;BRIDGE
DiG-Flow, 2025-12-1, 2025-12-1, https://arxiv.org/pdf/2512.01715, https://beingbeyond.github.io/DiG-Flow,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Compute a distributional discrepancy between observation and action embeddings to guide residual feature updates for robust flow matching,Predictive Modeling,LIBERO;RoboCasa,LIBERO;RoboCasa
RAGNet, 2025-7-31, 2025-12-1, https://arxiv.org/pdf/2507.23734, https://github.com/Dexmal-AI/RAGNet, Dataset Construction and Benchmarking Standards, Evaluation and Benchmark, construct a large-scale reasoning-based affordance segmentation dataset and propose AffordanceNet for open-world grasping, -, HANDAL;OXE;EgoObjects;GraspNet, HANDAL;GraspNet Novel;3DOI;RLBench
VLA-4D, 2025-11-21, 2025-12-1, https://arxiv.org/pdf/2511.17199, -, Multi-Modal Fusion and Physical World Representation, From 2D Images to SPatial Temporal Representations, Embed 3D positions and 1D time into visual features and extend actions with temporal variables for coherent manipulation, Predictive Modeling, Scan2Cap;ScanQA;ScanRef;LIBERO, LIBERO
LatBot, 2025-11-28, 2025-12-1, https://arxiv.org/pdf/2511.23034, https://mm-robot.github.io/distill_latent_action, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Learn instruction-guided latent actions from multi-frame videos and jointly decode future frames and inter-frame actions, BC and Predictive Modeling, OXE;AgiBot;EgoDex;DROID, SIMPLER;LIBERO;Franka real-robot tasks
DeepThinkVLA, 2025-10-31, 2025-12-8, https://arxiv.org/pdf/2511.15669, https://github.com/wadeKeith/DeepThinkVLA, From Complex Instructions to Robust and Real-Time Execution, Real-Time Execution and Computing Efficiency, Use a hybrid-attention decoder with SFT then outcome-based RL to align reasoning with actions, BC and RL, LIBERO demonstrations;embodied CoT dataset, LIBERO
Mantis, 2025-11-20, 2025-12-8, https://arxiv.org/pdf/2511.16175, https://github.com/zhijie-group/Mantis, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Disentangle visual foresight from action learning using a diffusion transformer head with latent action queries and progressive multimodal training, BC and Predictive Modeling, Something-Something V2;DROID;LLaVA-Instruct and 38 multimodal datasets, LIBERO
X-VLA, 2025-10-11, 2025-12-8, https://arxiv.org/pdf/2510.10274, https://thu-air-dream.github.io/X-VLA/, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Learn embodiment-specific soft prompts to absorb cross-embodiment heterogeneity and enable scalable pretraining and efficient adaptation, BC and Predictive Modeling, AGIBOT-beta;Droid;RoboMind;Soft-FOLD, LIBERO;Simpler-WidowX;Calvin;RoboTwin-2.0;VLABench
MergeVLA, 2025-11-24, 2025-12-8, https://arxiv.org/pdf/2511.18810, https://mergevla.github.io, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Introduce sparsely activated LoRA masks and cross-attention-only action experts with a training-free task router to enable mergeable multi-skill VLA policies, BC, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robot, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robo
GigaWorld-0, 2025-11-30, 2025-12-8, https://arxiv.org/pdf/2511.19861, https://giga-world-0.github.io, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Unify video generation and 3D physics-aware reconstruction to synthesize controllable embodied interaction data, BC and Predictive Modeling and RL, AgiBot World;RoboMind;proprietary in-house robotic platforms, PBench Robot Set;DreamGen Bench
HiMoE-VLA, 2025-12-05, 2025-12-8, https://arxiv.org/pdf/2512.05693, https://github.com/ZhiyingDu/HiMoE-VLA, Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution;Multi-Modal Fusion and Physical World Representation, Open-World Generalization;Real-Time Execution and Computing Efficiency;Dynamic and Predictive World Models, Use a hierarchical mixture of experts with action space and heterogeneity balancing experts to enable cross domain transfer;Cache intermediate VLM key value pairs for faster inference without degrading performance;Train actions with flow matching to model multimodal action distributions, BC and Predictive Modeling, OXE;ALOHA, CALVIN;LIBERO
HiF-VLA, 2025-12-10, 2025-12-15, https://arxiv.org/pdf/2512.09928, https://hifvla.github.io, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution, From 2D Images to SPatial Temporal Representations;Real-Time Execution and Computing Efficiency, Leverage low-dimensional motion vectors for hindsight foresight and action fusion in a unified latent space;Use compact motion representations to expand temporal reasoning with negligible latency, BC and Predictive Modeling, OXE;LIBERO, LIBERO-Long;CALVIN ABC
GLaD, 2025-12-10, 2025-12-15, https://arxiv.org/pdf/2512.09619, -, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning, From 2D Images to SPatial Temporal Representations;Open-World Generalization, Distill geometric features from a frozen VGGT teacher into LLM hidden states for visual tokens to fuse 3D priors;Pretrain on Bridge then fine tune with LoRA for robust policy generalization, BC, Bridge Data, LIBERO;LIBERO-PRO
ViFailback, 2025-12-03, 2025-12-15, https://arxiv.org/pdf/2512.02787, https://x1nyuzhou.github.io/vifailback.github.io, Dataset Construction and Benchmarking Standards;From Complex Instructions to Robust and Real-Time Execution;Security Interpretability and Reliable Interaction, Evaluation and Benchmark;Error Detection and Autonomous Recovery;Interpretability and Trustworthy Interaction, Build a large real-world failure VQA dataset and benchmark for diagnosis and correction;Use a VLM to detect localize and classify failures then generate textual and visual corrective guidance;Use explicit on-frame visual symbols to provide interpretable corrective cues, -, ViFailback dataset, ViFailback-Bench Lite;ViFailback-Bench Hard
RoboWheel, 2025-12-02, 2025-12-15, https://arxiv.org/pdf/2512.02729, https://zhangyuhong01.github.io/Robowheel, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Sim-to-real Gap in Deployment, Converts human hand-object interaction videos from diverse sources into training-ready supervision via a physics-aware reconstruction pipeline;Uses a simulation-augmented data flywheel with domain randomization in Isaac Sim to enrich trajectory distributions for robust real-world transfer, BC and RL, HORA;DexYCB;OakInk, Real-World-Tasks;OakInk
BayesVLA, 2025-12-12, 2025-12-22, https://arxiv.org/pdf/2512.11218, https://xukechun.github.io/papers/BayesVLA, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Decompose policy into vision-action prior and language-conditioned likelihood to mitigate modality imbalance, BC, DROID;LIBERO, LIBERO;LIBERO-PRO
Motus, 2025-12-15, 2025-12-22, https://arxiv.org/pdf/2512.13030, https://motus-robotics.github.io/motus, Multi-Modal Fusion and Physical World Representation;Dataset Construction and Benchmarking Standards, Dynamic and Predictive World Models;Multi-Source Heterogeneous Data, Integrates video generation and action experts via Mixture-of-Transformer architecture with a UniDiffuser-style scheduler;Introduces latent actions derived from optical flow to unify large-scale heterogeneous data across embodiments, BC and Predictive modeling, RoboTwin;LIBERO;VLAbench;AC-One Data;Agilex-Aloha-2 Data, RoboTwin;LIBERO-Long;VLAbench
VLSA-AEGIS, 2025-12-09, 2025-12-22, https://arxiv.org/pdf/2512.11891, https://vlsa-aegis.github.io/, Security Interpretability and Reliable Interaction;Dataset Construction and Benchmarking Standards, Reliability and Safety Assurance;Evaluation and Benchmark, Introduce a plug-and-play safety constraint layer formulated via control barrier functions into VLA models;Construct a comprehensive safety-critical benchmark SafeLIBERO spanning distinct manipulation scenarios with varying complexities, -, -, SafeLIBERO
OXE-AugE, 2025-12-15, 2025-12-22, https://arxiv.org/pdf/2512.13100, https://OXE-AugE.github.io/, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Open-World Generalization, Augments existing datasets with diverse robot embodiments using a scalable pipeline combining simulation rendering and learned masks;Fine-tunes generalist policies on augmented data to improve zero-shot transfer to unseen embodiments, BC, OXE;OXE-AugE;Bridge Data, Robosuite;Bridge Data
DexGrasp-VLA,2025-12-13, 2025-12-22,https://arxiv.org/pdf/2511.00139,https://dexvla-seed.github.io/dex-vla, Dataset Construction and Benchmarking Standards;Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning,Multi-Source Heterogeneous Data;The GAP between Semantics Perception and Physical Interaction;Continual Learning and Incremental Skill Acquisition,Propose a Shared Autonomy framework that partitions control along macro-micro motion domains for efficient data collection;Develop an Arm-Hand Feature Enhancement module to explicitly capture distinct latent features of arm and hand movements;Implement a Corrective Human-in-the-loop Teleoperation system to enable continuous policy improvement via failure recovery,BC and Predictive modeling,LSTM Pretraining Dataset;DexGrasp-VLA Hand Policy Dataset;End-to-End Arm-Hand VLA Dataset;Corrective Intervention Datasets,Real-world-Tasks;Long-horizon manipulation tasks;Industrial peg-in-hole assembly
VL-JEPA, 2025-12-11, 2025-12-22,https://arxiv.org/pdf/2512.10942,-,Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution,Dynamic and Predictive World Models;Real-Time Execution and Computing Efficiency,Predict continuous embeddings of target texts in an abstract representation space using a joint embedding predictive architecture;Enable selective decoding by invoking the text decoder only when significant semantic changes are detected in the predicted embedding stream,Predictive modeling,Datacomp;YFCC-100M;Ego4D;HowTo100M;PLM-Image-Auto;PLM-Video-Auto,Something-Something V2;EgoExo4D;Kinetics-400;MSR-VTT;ActivityNet;YouCook2;GQA;TallyQA;POPE;WorldPrediction-WM
Human to Robot, 2025-12-16, 2025-12-22, https://www.physicalintelligence.company/download/human_to_robot.pdf, https://www.physicalintelligence.company/research/human_to_robot, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Co-train human videos as an additional embodiment with robot data using unified trajectory and sub-task prediction objectives, BC and Predictive modeling, Human Video Data;Robot Teleoperation Data, Bussing;Spice;Dresser;Sort Eggs
WholeBodyVLA,2025-12-15,2025-12-22, https://arxiv.org/pdf/2512.11047,https://opendrivelab.com/WholeBodyVLA,Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution,Open-World Generalization;Real-Time Execution and Computing Efficiency,Train separate locomotion and manipulation latent action models on human videos to supervise VLA training;Employ a discrete command interface with two-stage curriculum RL policy for precise execution,BC and Predictive modeling and RL,Human egocentric videos;AgiBot World;Collected teleoperation trajectories,Real-World Tasks
VideoVLA, 2025-12-07,2025-12-22,  https://arxiv.org/pdf/2512.06963, https://videovla-nips2025.github.io/, Generalization and Adaptation for Continuous Learning;Multi-Modal Fusion and Physical World Representation, Open-World Generalization;Dynamic and Predictive World Models, Leverage pre-trained video generation models and a dual-prediction strategy to transfer physical knowledge to robotic manipulation;Jointly denoise video latents and action vectors within a unified multi-modal diffusion transformer architecture, BC and Predictive modeling, OXE, SIMPLER
MiVLA,2025-12-17,2025-12-22, https://arxiv.org/pdf/2512.15411,-,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Utilizes kinematic rules with left/right hand coordinate systems for bidirectional alignment between human and robot action spaces,BC and Predictive modeling,RoboTwin;Human Videos,RoboTwin-2.0
EVOLVE-VLA, 2025-12-16, 2025-12-22, https://arxiv.org/pdf/2512.14666, https://showlab.github.io/EVOLVE-VLA, Generalization and Adaptation for Continuous Learning, Online Interaction and Reinforcement Learning, Introduce accumulative progress estimation mechanism and progressive horizon extension strategy to tame noisy reward signals for test-time training, BC and RL, LIBERO, LIBERO
ManualVLA, 2025-12-01, 2025-12-22, https://arxiv.org/pdf/2512.02013, https://sites.google.com/view/maunalvla, From Complex Instructions to Robust and Real-Time Execution;Generalization and Adaptation for Continuous Learning, Hierarchical Planning and Task Decomposition;Sim-to-real Gap in Deployment, Design a unified Mixture-of-Transformers framework that selectively activates planning and action experts for coherent manual generation and execution;Construct a high-fidelity digital twin toolkit using 3D Gaussian Splatting to synthesize large-scale training data, BC and Predictive modeling, OXE;DROID;RoboMind, RLBench
PolaRiS, 2025-12-18, 2025-12-22, https://arxiv.org/pdf/2512.16881, https://polaris-evals.github.io, Dataset Construction and Benchmarking Standards, Evaluation and Benchmark, Utilizes neural reconstruction methods to turn video scans into interactive simulation environments and develops a co-training recipe to bridge real-to-sim gaps, BC, DROID;PolaRiS Simulation Dataset;LIBERO, PolaRiS;RoboArena;LIBERO
ISS,2025-12-17,2025-12-22,https://arxiv.org/pdf/2512.15020, -, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution,Dynamic and Predictive World Models;Real-Time Execution and Computing Efficiency,Introduces an implicit scene supervision module that predicts future point cloud features to enforce long-term geometric consistency;Uses a streamlined DiT architecture with sparse point cloud encoding to improve inference speed and training efficiency,BC and Predictive Modeling,Adroit;MetaWorld,Adroit;MetaWorld
GeoPredict, 2025-12-18, 2025-12-22, https://arxiv.org/pdf/2512.16811, https://jingjingqian75.github.io/GeoPredict-Page/, Multi-Modal Fusion and Physical World Representation, From 2D Images to SPatial Temporal Representations;Dynamic and Predictive World Models, Constructs a predictive 3D Gaussian geometry module to forecast workspace geometry with track guided refinement along future keypoint trajectories;Augments a continuous action policy with predictive kinematic priors that encode motion history and predict multi step 3D keypoint trajectories, BC and Predictive Modeling, RoboCasa;LIBERO, RoboCasa;LIBERO
AFI, 2025-12-08, 2025-12-22, https://arxiv.org/pdf/2512.07472, -, Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution, Open-World Generalization;Error Detection and Autonomous Recovery, Employ 3D Spatial Affordance Fields to guide VLA behavior in out-of-distribution scenarios;Detect memory traps using proprioception and execute affordance-guided rollback for recovery, BC, Self-built Data;LIBERO, Real-world manipulation tasks;LIBERO-PRO
PhysBrain, 2025-12-19, 2025-12-22, https://arxiv.org/pdf/2512.16793, https://zgc-embodyai.github.io/PhysBrain/, Dataset Construction and Benchmarking Standards;Multi-Modal Fusion and Physical World Representation, Multi-Source Heterogeneous Data;The GAP between Semantics Perception and Physical Interaction, Transform first-person videos into multi-level schema-driven VQA supervision with enforced evidence grounding and temporal consistency to construct the E2E-3M dataset;Train an egocentric-aware embodied brain on the E2E-3M dataset to bridge vision language models with physical intelligence and enable sample-efficient VLA fine-tuning, BC and Predictive Modeling, Ego4D;BuildAI;EgoDex;FineVision;Bridge;Fractal, EgoThink;SimplerEnv
MM-ACT⭐, 2025-12-08, 2025-12-22, https://arxiv.org/pdf/2512.00975, https://github.com/HHYHRHY/MM-ACT, From Complex Instructions to Robust and Real-Time Execution;Multi-Modal Fusion and Physical World Representation, Real-Time Execution and Computing Efficiency;Hierarchical Planning and Task Decomposition, Adopts a one-step parallel decoding strategy for action generation to achieve low-latency inference;Integrates text image and action in shared token space to perform task planning and future image prediction under shared context, BC and Predictive Modeling, LIBERO;RoboTwin, LIBERO;RoboTwin;Franka Real-world
WALL-OSS⭐, 2025-09-08, 2025-12-22, https://arxiv.org/pdf/2509.11766, https://x2robot.com/en/research/68bc2cde8497d7f238dde690, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution;Dataset Construction and Benchmarking Standards, The GAP between Semantics Perception and Physical Interaction;From 2D Images to SPatial Temporal Representations;Hierarchical Planning and Task Decomposition;Multi-Source Heterogeneous Data, Employ a tightly coupled Mixture-of-Experts architecture with static routing to align action and vision-language features;Leverage embodied VQA and discrete action priors to strengthen spatial reasoning and progress modeling;Develop Unified Cross-Level CoT to seamlessly unify instruction reasoning subgoal decomposition and fine-grained action synthesis;Aggregate over 10000 hours of data from self-collected robot trajectories open-source datasets and multimodal VQA with unified specifications, BC and Predictive Modeling, AgiBot World;Droid;Bc_z;RH20T;Furniture_bench;Fractal;Bridge Data v2, Embodied VQA Benchmark;Set-Table;Tidy-Bedroom;Place-by-Color;Block-Spell;Collect-Waste;Pick-Place-Cup
GENMANIP⭐, 2025-06-12, 2025-12-22, https://arxiv.org/pdf/2506.10966, -, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Evaluation and Benchmark;Open-World Generalization, Introduce a realistic tabletop simulation platform tailored for policy generalization studies with 200 human curated scenarios;Leverage LLM driven task oriented scene graph to synthesize diverse tasks using 10K annotated 3D object assets, BC, Objaverse;GRUtopia;PartNet-Mobility, GENMANIP-BENCH
ROBOGROUND⭐, 2025-04-30, 2025-12-22, https://arxiv.org/pdf/2504.21530, https://robo-ground.github.io, Generalization and Adaptation for Continuous Learning;Dataset Construction and Benchmarking Standards, Open-World Generalization;Evaluation and Benchmark, Leverage grounding masks as effective intermediate representations to provide spatial guidance for policy networks;Design an automated pipeline to generate simulated manipulation data with diverse objects and instructions, BC, RoboCasa;Objaverse, RoboCasa
CronusVLA⭐, 2025-10-30, 2025-12-22, https://arxiv.org/pdf/2506.19816, -, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution, From 2D Images to SPatial Temporal Representations;Real-Time Execution and Computing Efficiency, Proposes a two-stage framework with single-frame pretraining and multi-frame post-training using feature chunking to aggregate temporal information;Optimizes inference speed by predicting learnable features and using a queue mechanism for feature caching, BC and Predictive Modeling, OXE;Bridge Data v2;Fractal;LIBERO, SimplerEnv;LIBERO;SimplerEnv-OR
InternVLA-M1⭐, 2025-10-15, 2025-12-22, https://arxiv.org/pdf/2510.13778, https://internrobotics.github.io/internvla-m1.github.io/, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning;Dataset Construction and Benchmarking Standards, The GAP between Semantics Perception and Physical Interaction;Open-World Generalization;Multi-Source Heterogeneous Data, Employs a two-stage pipeline combining spatial grounding pre-training with spatially guided action post-training to bridge instructions and actions;Utilizes synthetic co-training and spatial prompting to achieve robust performance on unseen objects and long-horizon tasks;Builds a scalable simulation engine to generate large-scale diverse manipulation episodes and spatial grounding annotations, BC and Predictive Modeling, InternData-M1;RefCOCO;RoboRef It;OXE;LIBERO, SimplerEnv;LIBERO
X-VLA⭐,2025-10-14,2025-12-22,https://arxiv.org/pdf/2510.10274,https://thu-air-dream.github.io/X-VLA/,Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning,Multi-Source Heterogeneous Data;Open-World Generalization,Introduces distinct learnable soft prompt embeddings for each data source to absorb embodiment-specific variations;Employs a two-step adaptation process that warms up prompts before joint policy finetuning,BC and Predictive Modeling,Droid;RoboMind;AgiBot,LIBERO;Simpler;Calvin;RoboTwin-2.0;VLABench;NAVSIM