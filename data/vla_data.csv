略称,Year,Paper URL,Website URL,Challenge Tag,Sub-Challeng Tag,How to Solve,Training Type,Dataset,Evaluation
OTTER,2021,https://arxiv.org/pdf/2503.03734,https://ottervla.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Introdues a text-aware feature extraction which preserves semantics aligned with task descriptions,BC,OXE; DS-PnP;DS-ALL,LIBERO;Real-Robot Evaluation
LIV,2023,https://proceedings.mlr.press/v202/ma23b/ma23b.pdf,https://penn-pal-lab.github.io/LIV/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Introdues a contrastive framework on robot-control data to construct a joint vision-language embedding space,RL,EPIC-KITCHENS-100;MetaWorld;Franka Kitchen;Self-built Data,Franka Kitchen;Self-built Data;MetaWorld;Franka Kitchen
ACT-LLM,2025,https://arxiv.org/pdf/2506.21250,https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Formulates raw per- ceptual inputs into structured language representation,RL,CLIPORT,CLIPORT;VIMA-Bench
Look-Leap,2023,https://arxiv.org/pdf/2311.17842,robot-vila.github.io,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Structured action-plan generation from visual inputs,Predictive Modeling,Self-built Data,CLIPORT;Self-built Data
RT-2,2023,https://arxiv.org/abs/2307.15818,https://robotics-transformer.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Fine-tuning a pretrained VLM to directly output action tokens,BC,WebLI;Language Table,Seen Tasks;Self-built Data
Prompt-a-Robot-to-Walk,2023,https://arxiv.org/abs/2309.09969,https://prompt2walk.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Fine-tuning a pretrained VLM to directly output action tokens,BC and Predictive Modeling,None,MuJoCo;Isaac Gym
Grounding MLLMs,2024,https://arxiv.org/pdf/2406.07904,https://github.com/mbzuai-oryx/groundingLMM,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Fine-tuning a pretrained VLM to directly output action tokens,BC,CALVIN;MetaWorld;Habitat Pick,CALVIN;MetaWorld;Habitat Pick
OpenVLA,2024,https://arxiv.org/pdf/2406.09246,https://openvla.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Fine-tuning a pretrained VLM to directly output action tokens,BC,OXE,Bridge Data;Google Robot
CLIP-RT,2024,https://arxiv.org/pdf/2411.00508,https://clip-rt.github.io,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Extends CLIP-style vision-language alignment,BC,OXE,LIBERO
Humanoid-VLA,2025,https://arxiv.org/pdf/2502.14795,https://github.com/AllenXuuu/HumanVLA,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Pre-training language-action,BC and Predictive Modeling and RL,Motion Capture;Online Videos;Synthetic Data,Isaac Gym;T2M
VoxPoser,2023,https://arxiv.org/pdf/2307.05973,https://voxposer.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Generate intermediate programs and 3D affordance maps as strong intermediate representations by LLM,BC,Online Experiences,RLBench
Orion,2025,https://arxiv.org/pdf/2503.19755,https://xiaomi-mlab.github.io/Orion/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Introduces a high-level VLM planner with a separate low-level motion controller,BC,Bench2Drive base set; Chat-B2D Dataset;,nuScenes;Bench2Drive
Gemini RObotics,2025,https://arxiv.org/pdf/2503.20020,https://deepmind.google/blog/gemini-robotics-brings-ai-into-the-physical-world/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Introduces a high-level VLM planner with a separate low-level motion controller,BC and Predictive Modeling,Self-built Data,Manipulation Tasks
KnowledgeVLA,2025,https://arxiv.org/abs/2505.23705,https://www.pi.website/research/knowledge_insulation,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Introduces a high-level VLM planner with a separate low-level motion controller,BC,OXE,LIBERO;DROID
Beyond Sight,2025,https://arxiv.org/pdf/2501.04693,https://fuse-model.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Incorporating additional modalities,BC ,OXE,Self-built Data;Octo
RH-20T,2023,https://arxiv.org/pdf/2307.00595,https://rh20t.github.io./,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Incorporating additional modalities,BC , RH20T, RH20T
TouchVLA,2025,https://arxiv.org/pdf/2507.17294,https://clear-nus.github.io/blog/vla-touch,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Incorporating additional modalities,BC ,Self-built Data,Self-built Data
TLA,2025,https://arxiv.org/pdf/2503.08548,https://sites.google.com/view/tactile-language-action/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Introduces tactile perception,BC,TLA,Custom Contact-Rich Manipulation Benchmark
OmniVTLA,2025,https://arxiv.org/pdf/2508.08706,https://github.com/linchangyi1/Awesome-Touch,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Constructs a se mantically aligned tactile encoder ,BC ,Self-built Data,Real-Robot Evaluation
Tactile-VLA,2025,https://arxiv.org/pdf/2507.09160,https://jialeihuang.github.io/tactileVLA.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Ranging from deep fusion across the full pipeline,BC ,Self-built Data,Real-Robot Evaluation
ForceVLA,2025,https://arxiv.org/pdf/2505.22159,https://sites.google.com/view/forcevla2025/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Modular mixture-of-experts (MoE) fusion ,BC ,Force-VLA-Dataset,Force-VLA-Benchmark
MultiGen,2025,https://arxiv.org/html/2507.02864v2,https://multigen-audio.github.io/,Multi-Modal Fusion and Physical World Representation,The GAP between Semantics Perception and Physical Interaction,Uses multimodal generation for simulated multi-modal data,BC ,Self-built Data;EPIC-Kitchens,Real-Robot Evaluation
Depth Helps,2024,https://arxiv.org/pdf/2408.05107,https://gewu-lab.github.io/DepthHelps-IROS2024/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Treats depth as a supervisory signal,BC,LIBERO;Self-built Data,LIBERO
RoboFlamingo-Plus,2025,https://arxiv.org/pdf/2503.19510,-,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Fuses preprocessed depth maps  with RGB features,BC ,CALVIN,CALVIN
PointVLA,2025,https://arxiv.org/pdf/2503.07511,https://pointvla.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,integrates point cloud inputs into pretrained VLA models to improve spatial reasoning without modifying the backbone,BC,Self-built Data,Self-built Data
Leo,2023,https://arxiv.org/pdf/2311.12871,https://embodied-generalist.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,unify 2D and 3D modalities,BC,LEO,CLIPORT;AI Habitat ObjNav
GeoVLA,2025,https://arxiv.org/pdf/2508.09071,https://linsun449.github.io/GeoVLA,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,unify 2D and 3D modalities,BC,OXE,LIBERO;ManiSkill2
FP3,2025,https://arxiv.org/pdf/2503.08950,https://3d-foundation-policy.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Uses a point-cloud–centric pipeline reconstruction,BC ,DROID;Self-built Data,-
SoFar,2025,https://arxiv.org/pdf/2502.13143,https://qizekun.github.io/sofar/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Constructs semantic 3D scene graphs by integrating VLM-recognized objects and point-cloud orientation cues,BC,OrienText300K;Objaverse,Open6DOR
Weakly-Supervised 3D,2025,https://arxiv.org/pdf/2312.09625,-,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Leverages CLIP’s 2D–text alignment for weakly supervised 3D semantic transfer,BC ,ReferIt3D;ScanRefer,ReferIt3D;ScanRefer
LLM-3DP,2025,https://arxiv.org/pdf/2501.18733,https://lmm-3dp-release.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Fuses 2D semantic features via back-projection with point-cloud geometry for unified semantic-geometric representation,BC and Predictive Modeling,Self-built Data,RLBench
OccLLaMA,2024,https://arxiv.org/pdf/2409.03272,https://vilonge.github.io/OccLLaMA_Page/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Assigns semantic labels to 3D  voxels for spatial reasoning,Predictive Modeling,NuScenes;Occ3D,nuScenes
RoboMM,2024,https://arxiv.org/pdf/2412.07215,-,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Incorporates multi-view temporal modeling to generate unified 3D  occupancy grids.,BC,OXE;CALVIN,CALVIN;MetaWorld;LIBERO
TraceVLA,2024,https://arxiv.org/pdf/2412.10345,https://tracevla.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Extends this to a 4D  perspective by incorporating time,BC ,Bridge Data;OXE,SimplerEnv;LIBERO;WidowX-250
ARM4R,2025,https://arxiv.org/pdf/2502.13142,https://arm4r.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Learns space–time coupling by predicting the evolution of 3D point trajectories,BC and Predictive Modeling,Epic-Kitchens100;RLBench,RLBench;Kinova Gen3
SpatialVLA,2025,https://arxiv.org/pdf/2501.15830,spatialvla.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Uses positional encoding and adaptive spatial grids to project 2D semantics into 3D and generate space-action knowledge graphs,BC ,OXE;RH20T;Bridge Data,SimplerEnv;LIBERO
Evo-0,2025,https://arxiv.org/pdf/2507.00416,https://mint-sjtu.github.io/Evo-0.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Attaches external geometric modules atop a frozen VLM,BC,RLBench,RLBench
AC-DiT,2025,https://arxiv.org/pdf/2507.01961,https://ac-dit.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Leverages diffusion-based conditional modeling to estimate depth reliability without full 3D reconstruction,BC,Self-built Data;RoboTwin;ManiSkill-HAB,ManiSkill-HAB;RoboTwin
BridgeVLA,2025,https://arxiv.org/pdf/2506.07961,https://bridgevla.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Converts point clouds into multiple rendered 2D views,BC,RoboPoint;RLBench;Self-built Data,RLBench;COLOSSEUM;GemBench
OG-VLA,2025,https://arxiv.org/abs/2506.01196,https://og-vla.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,generates orthographic projections to recover 3D pose,RL,ARNOLD;COLOSSEUM,ARNOLD;COLOSSEUM
RoboPoint,2024,https://arxiv.org/pdf/2406.10721,https://robo-point.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Leverages 2D keypoint back-projection to form structured 3D action cues,Predictive Modeling,VQA;Self-built Data,RoboRefIt;WHERE2PLACE
VoxPoser,2023,https://arxiv.org/pdf/2307.05973,https://voxposer.github.io/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Leverages LLM-guided code to generate dense voxel-value maps linking linguistic constraints to spatial geometry,predictive Modeling,null,Real-Robot Evaluation
Spatial Traces,2025,https://arxiv.org/pdf/2508.09032,https://ampiromax.github.io/ST-VLA,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,"Fuses tracked keypoints with depth maps, encoding structure and dy namics in a unified 2D input",BC,Bridge Data,SimplerEnv
A0,2025,https://arxiv.org/pdf/2504.12636,https://a-embodied.github.io/A0/,Multi-Modal Fusion and Physical World Representation,From 2D Images to SPatial Temporal Representations,Predicts interaction points and trajectories in 2D and then lifts them into 3D via depth projection,RL,PixMo-One-Point;HOI4D-22k;DROID-3k;Maniskill-5k,HOI4D-22k;DROID-3k;Maniskill-5k;Real-Robot Evaluation
TriVLA,2025,https://arxiv.org/pdf/2507.01424,https://robertwyq.github.io/univla.github.io/,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Augments a video diffusion model to produce  multi-step visual rollouts,BC ,Bridge Data;CALVIN ABC;MetaWorld,CALVIN ABC;LIBERO;MetaWorld
UP-VLA,2025,https://arxiv.org/pdf/2501.18867,https://github.com/CladernyJorn/UP-VLA,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages key subgoal image prediction to represent the next salient task state,BC,Bridge Data;Self-built Data,CALVIN
CoT-VLA,2025,https://arxiv.org/abs/2503.22020,https://cot-vla.github.io/,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages key subgoal image prediction to represent the next salient task state,BC,OXE;EPIC-KITCHENS-100;Something-Something V2;Bridge Data,LIBERO
DreamVLA,2025,https://arxiv.org/pdf/2507.04447,https://zhangwenyao1.github.io/DreamVLA/,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,"Predicting task-critical cues (dynamic regions, depth, and affordance features)",BC ,CALVIN;Self-built Data,CALVIN ABC;LIBERO;
V-jepa 2,2025,https://arxiv.org/pdf/2506.09985,https://ai.meta.com/blog/v-jepa-2-world-model-benchmarks,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages latent-space encoding and prediction to model future state evolution,Predictive Modeling,VideoMix22M;Droid,Something-Something V2;ImageNet;
LUMOS,2025,https://arxiv.org/pdf/2503.10370,http://lumos.cs.uni-freiburg.de/,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages multi-step internal rollouts in a learned world model to evaluate action sequences and select an optimal plan,BC,CALVIN;Self-built Data,CALVIN Challenge
FlowVLA,2025,https://arxiv.org/abs/2508.18269,https://irpn-lab.github.io/FlowVLA/,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages a visual chain-of-thought mechanism to forecast future frames and synthesize physically consistent scenes,BC and Predictive Modeling,LIBERO;SimplerEnv;Bridge Data,LIBERO;SimplerEnv-WidowX;AgileX Cobot;Bridge Data
WorldVLA,2025,https://arxiv.org/pdf/2506.21539,https://github.com/alibaba-damo-academy/RynnVLA-002,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages learned world dynamics to model low-level physics and synthesize future physical evolution,BC and Predictive Modeling,LIBERO-90,LIBERO
VLM-in-the-loop,2025,https://arxiv.org/pdf/2502.01828,https://yilin-wu98.github.io/forewarn/,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages internal multi-step rollouts in a world model to evaluate and select action sequences,BC and Predictive Modeling,Self-built Data,Real-Robot Evaluation
MinD,2025,https://arxiv.org/abs/2502.07591,https://github.com/news-vt/DMWM,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages internal multi-step rollouts to evaluate long-horizon outcomes and select optimal actions,RL ,RT-1;RoboMind;OXE;,Franka Research 3
WMPO,2025,https://arxiv.org/pdf/2511.09515,https://wm-po.github.io/,Multi-Modal Fusion and Physical World Representation,Dynamic and Predictive World Models,Leverages imagined interaction in a video world model to replace costly physical interaction,Predictive Modeling and RL,OXE;Cobot Mobile ALOHA;,Mimicgen simulation;Real-Robot Evaluation
OE-VLA,2025,https://arxiv.org/pdf/2505.11214,https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation,From Complex Instructions to Robust and Real-Time Execution,Parsing Complex Instructions,Leverages a shared visual encoder and text tokenizer to produce strictly interleaved token streams,BC and Predictive Modeling,MGrounding;CALVIN,OE-CALVIN_base
Interleave-VLA,2025,https://arxiv.org/pdf/2505.02152,https://interleave-vla.github.io/Interleave-VLA-Anonymous/,From Complex Instructions to Robust and Real-Time Execution,Parsing Complex Instructions,Leverages special tokenizer tags to insert image features seamlessly into text sequences,BC,Open Interleaved X-Embodiment Dataset,VIMA-Bench
TinkAct,2025,"""https://arxiv.org/pdf/2507.16815",https://jasper0314-huang.github.io/thinkact-vla/,From Complex Instructions to Robust and Real-Time Execution,Parsing Complex Instructions,infers and verifies the in tended target via scene parsing and feedback,Predictive Modeling and RL,HowTo100M; COIN; CrossTask,Visual Planning for Assistance
DEEPTHINKVLA,2025,https://arxiv.org/pdf/2511.15669,https://github.com/wadeKeith/DeepThinkVLA,From Complex Instructions to Robust and Real-Time Execution,Parsing Complex Instructions,Leverages causal chain-of-thought and outcome-driven RL to resolve ambiguity and align subgoals,BC and Predictive Modeling,Embodied CoT,LIBERO
InSpire,2025,https://arxiv.org/pdf/2505.13888,https://koorye.github.io/proj/Inspire/,From Complex Instructions to Robust and Real-Time Execution,Parsing Complex Instructions,leverages explicit spatial queries to prompt the policy for target-robot relative location,BC ,LIBERO-90;CALVIN,LIBERO
AskToAct,2025,https://arxiv.org/pdf/2503.01940,https://github.com/emrecanacikgoz/awesome-conversational-agents,From Complex Instructions to Robust and Real-Time Execution,Parsing Complex Instructions,leverages explicit spatial queries to auto-fill missing target-robot information,BC,xlam-IC,Taskbench-IC
OneTwoVLA,2025,https://arxiv.org/pdf/2505.11917,https://one-two-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,leverages structured textual reasoning to generate scene descriptions high-level plans and next-step instructions,BC and Predictive Modeling and RL,Human Experts Demonstration,OneTwoVLA(self create)
PI0.5,2025,https://arxiv.org/pdf/2504.16054,https://www.pi.website/blog/pi05,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,embeds hierarchical reason ing within a single inference chain,BC and Predictive Modeling,Diverse Mobile Manipulator;Diverse Multi-Environment non-mobile robot ;Cross-Embodiment laboratory,PI0.5
Hi Robot,2025,https://arxiv.org/pdf/2502.19417,https://www.pi.website/research/hirobot,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,employ a two-layer scheme where a VLM parses  instructions into atomic sub-tasks,BC and Predictive Modeling,Teleoperated robot demonstrations,Hi Robot
LoHoVLA,2025,https://arxiv.org/pdf/2506.00411,-,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,leverages structured textual reasoning to generate scene descriptions high-level plans and next-step instructions,BC and Predictive Modeling,LoHoSet,LoHoRavens
CoT-VLA,2025,https://arxiv.org/pdf/2503.22020,https://cot-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,employs pixel-level subgoal images as explicit intermediates,BC,OXE; EPIC-KITCHENS; Something-Something V2,LIBERO
Embodied-SlotSSM,2023,https://www.arxiv.org/pdf/2511.11478,https://libero-mem.github.io/,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,employs slot-based object-centric representations to create structured visual intermediates ,BC ,LIBERO-Goal,LIBERO-Mem
RT-Affordance,2024,https://arxiv.org/pdf/2411.02704,https://snasiriany.me/rt-affordance,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,plans tasks by breaking manipulation into manageable affordance steps,BC and Predictive Modeling,RT-1 ;MOO,RT-Affordance
CoA-VLA,2025,https://arxiv.org/pdf/2412.20451,https://chain-of-affordance.github.io/,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,Treats each affordance link as an implicit planning signal,BC and Predictive Modeling,Droid,LIBERO
VLP,2025,https://arxiv.org/pdf/2401.05577,https://github.com/autodriving-heart/CVPR-2024-Papers-Autonomous-Driving,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,builds a fine-grained library for data-efficient reuse of manipulation patterns.,BC and Predictive Modeling,nuScenes,open-loop planning
Agentic Robot,2025,https://arxiv.org/pdf/2505.23450,https://agentic-robot.github.io/,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,Produces clear step subgoals sequences for verifiable task decomposition,BC and Predictive Modeling,OXE,LIBERO
RoboBrain,2025,https://arxiv.org/pdf/2502.21257,https://superrobobrain.github.io/,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,Leverages a hierarchical framework to map abstract instructions to executable atomic actions,BC and Predictive Modeling and RL,LCS-558K; Image-4M; SI-3.2M,RoboVQA; OpenEQA; ShareRobot
DexVLA,2025,https://arxiv.org/pdf/2502.05855,https://github.com/juruobenruo/DexVLA,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,Leverages temporal alignment to automatically annotate semantic sub-steps in long-horizon sequences,BC and Predictive Modeling,DexVLA(self collecting),LIBERO
AgiBot,2025,https://arxiv.org/pdf/2503.06669,https://opendrivelab.com/AgiBot-World/,From Complex Instructions to Robust and Real-Time Execution,Hierarchical Planning and Task Decomposition,Leverages explicit skills during data collection to learn latent action tokens that compress high-dimensional control,BC and Predictive Modeling,AgiBot;OXE,AgiBot
Yell At Your Robot,2024,https://arxiv.org/pdf/2403.12910,https://yay-robot.github.io/,From Complex Instructions to Robust and Real-Time Execution,Error Detection and Autonomous Recovery,Leverages  real-time language feedback for instant behavioral correction,BC and Predictive Modeling and RL,Yell At Your Robot,Yell At Your Robot
CLIP-RT,2024,https://arxiv.org/pdf/2411.00508,https://clip-rt.github.io/,From Complex Instructions to Robust and Real-Time Execution,Error Detection and Autonomous Recovery,Leverages language feedback as an action template via similarity matching for retrain-free correction,,OXE; Self collecting,LIBERO
OneTwoVLA,2025,https://arxiv.org/pdf/2505.11917,https://one-two-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution,Error Detection and Autonomous Recovery,Actively queries humans to resolve uncertainty before acting,,OneTwoVLA,OneTwoVLA
CorrectNav,2025,https://arxiv.org/pdf/2508.10416,https://correctnav.github.io/,From Complex Instructions to Robust and Real-Time Execution,Error Detection and Autonomous Recovery,Leverages iterative self-correction by using the model's own error trajectories to generate corrective actions and data,BC and Predictive Modeling and RL,VLN-CE; VLN-CE R2R; LLaVA-Video,VLN-CE;R2R-CE;Val-Unseen
FPC-VLA,2025,https://arxiv.org/pdf/2509.04018,https://fpcvla.github.io/,From Complex Instructions to Robust and Real-Time Execution,Error Detection and Autonomous Recovery,Leverages a VLM to assess action semantics and generate corrective language feedback,BC and Predictive Modeling and RL,OXE;Bridge Data;Google Fractal,SIMPLER
Agentic Robot,2025,https://arxiv.org/pdf/2505.23450,https://agentic-robot.github.io/,From Complex Instructions to Robust and Real-Time Execution,Error Detection and Autonomous Recovery,Achieves autonomous correction via a plan-act-verify loop with VLM-based validation and recovery,BC,OXE; LIBERO,LIBERO-Spatial;LIBERO-Object;LIBERO-Goal
BitVLA,2025,https://arxiv.org/pdf/2506.07530,https://github.com/ustcwhy/BitVLA,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,achieves ultra-low-precision efficiency  via ternary 1-bit compression and distillation,BC,LLaVA 1.5-558k;MammoTH-VL,VQA
Evo-1,2025,https://arxiv.org/pdf/2511.04555,https://github.com/MINT-SJTU/Evo-1,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Provides a lightweight 77M-parameter design,BC,MetaWorld; RoboTwin,MetaWorld
SQAP-VLA,2025,https://arxiv.org/pdf/2509.09090,https://github.com/ecdine/SQAP-VLA,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Introduces perceptual pruning strategies on the basis of quantization,BC and Predictive Modeling,OXE,standard robotics simulation benchmark
TinyVLA,2025,https://arxiv.org/pdf/2409.12514,https://tiny-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Adopt lightweight backbones directly,BC ,LLaVA,MetaWorld
VLA-Adapter,2025,https://arxiv.org/pdf/2509.09372,https://vla-adapter.github.io/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages lightweight adapters to graft large-model knowledge into smaller policies,BC and Predictive Modeling,OXE; DROID,LIBERO
NORA,2025,https://arxiv.org/pdf/2504.19854,https://declare-lab.github.io/nora,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Adopt lightweight backbones directly ,BC and Predictive Modeling,OXE,Real-world WidowX-250
RoboMamba,2024,https://arxiv.org/pdf/2406.04339,https://sites.google.com/view/robomamba-web,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages a Mamba backbone for linear-time scaling and faster inference,BC,LLaVA-LCS 558K;LLaVA 1.5 655K; ShareGPT4V-SFT,VQAv2;OKVQA;GQA
MoLe-VLA,2025,https://arxiv.org/pdf/2503.20384,https://sites.google.com/view/mole-vla,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,leverages layer skipping to reduce FLOPs ,BC and Predictive Modeling,RLBench,RLBench
CEED-VLA,2025,https://arxiv.org/pdf/2506.13725,https://irpn-eai.github.io/CEED-VLA/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Design early exit mechanisms.,BC ,CALVIN; LIBERO,CALVIN ABC
DeeR-VLA,2024,https://arxiv.org/pdf/2411.02359,https://github.com/yueyang130/DeeR-VLA,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Design early exit mechanisms. ,BC and Predictive Modeling,CALVIN; LAION-2B,CALVIN
VLA-Cache,2025,https://arxiv.org/pdf/2502.02175,https://vla-cache.github.io/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Uuses adaptive caching that differentiates static and dynamic tokens,BC and Predictive Modeling and RL,CLVR_Jaco_Play,LIBERO
SpecPrune-VLA,2025,https://arxiv.org/pdf/2509.05614,https://github.com/JiuTian-VL/Large-VLM-based-VLA-for-Robotic-Manipulation,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,performs action aware pruning conditioned on history and current observations,BC and Predictive Modeling,-,LIBERO
CogVLA,2025,https://arxiv.org/pdf/2508.21046,https://jiutian-vl.github.io/CogVLA-page/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,reduces computation through  instruction-driven visual token sparsification.,Predictive Modeling,LIBERO; Self collecting,LIBERO
AcceleratingVLA,2025,https://arxiv.org/pdf/2503.02310,https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages parallel decoding to generate full action chunks in one pass,BC and Predictive Modeling,CALVIN,CALVIN
OpenVLA-OFT,2025,https://arxiv.org/pdf/2502.19645,https://github.com/moojink/openvla-oft,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages parallel decoding to generate full action chunks in one pass,Predictive Modeling,ALOHA,LIBERO
Spec-VLA,2025,https://arxiv.org/pdf/2507.22424,https://github.com/PineTreeWss/SpecVLA,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages speculative decoding to emit candidate action tokens in one pass,BC,Generating by OpenVLA,LIBERO
FAST,2025,https://arxiv.org/pdf/2501.09747,https://www.pi.website/research/fast,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Compresses action sequences ,BC and Predictive Modeling and RL,DROID; Bridge Data; OXE,DROID
VQ-VLA,2025,https://arxiv.org/pdf/2507.01016,https://xiaoxiao0406.github.io/vqvla.github.io/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages a VQ-VAE tokenizer to compress long trajectories into compact discrete tokens,BC,OXE;LIBERO;ManiSkill;RLBench,LIBERO-10;LIBERO-GOAL;LIBERO-90
XR-1,2025,https://arxiv.org/pdf/2511.02776,https://xr-1-vla.github.io/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages VQ-VAE–learned discrete visual–motor tokens to guide policy learning,BC ,OXE;RoboMind;Ego4D;XR-D,XR-1
SmolVLA,2025,https://arxiv.org/pdf/2506.01844,https://github.com/huggingface/smollm,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages asynchronous execution to predict the next action chunk during current execution,BC ,Hugging Face ; LIBERO; MetaWorld,LIBERO
Time-Diffusion Policy,2025,https://arxiv.org/pdf/2506.09422,https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages a unified velocity field to replace time-varying denoising,BC ,RLBench,RLBench
Discrete Diffusion VLA,2025,https://arxiv.org/pdf/2508.20072,https://github.com/Liang-ZX/DiscreteDiffusionVLA,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Discretizes actions into tokens and employs masked diffusion with parallel prediction,BC ,OXE;Fractal;Bridge Data;LIBERO,SimplerEnv-Fractal
ECoT-Lite,2025,https://arxiv.org/pdf/2505.08243v1,https://github.com/MichalZawalski/embodied-CoT,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages reasoning traces during training while bypassing explicit reasoning at inference,BC,LIBERO;Bridge Data,LIBERO
V-JEPA,2025,https://arxiv.org/pdf/2506.09985,https://github.com/facebookresearch/vjepa2,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Predicting compressed semantic representations instead of raw pixels,Predictive Modeling,VideoMix22M; Droid,Kinetics-400;Something-Something V2
Fast-in-Slow,2025,https://arxiv.org/pdf/2506.01953,https://fast-in-slow.github.io/,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages a dual-system model coordinating slow reasoning and fast reactions,BC and Predictive Modeling,OXE;DROID;RoboMind,RLBench
AMS,2025,https://arxiv.org/pdf/2405.09045,https://github.com/AMS-Net/ams-net.github.io,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Introduces OS-level action context caching and replay mechanisms,BC ,AMSNet,MLLM4EDA
FedVLA,2025,https://arxiv.org/pdf/2508.02190,-,From Complex Instructions to Robust and Real-Time Execution,Real-Time Execution and Computing Efficiency,Leverages federated learning for efficient distributed VLA training,BC,OXE,MetaWorld
Octo,2024,https://arxiv.org/pdf/2405.12213,https://octo-models.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Pretrain Transformer on 800k trajectories and use lightweight adapters,BC and Predictive Modeling,OXE,WidowX
DexVLA,2025,https://arxiv.org/pdf/2502.05855,https://dex-vla.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Pretrain diffusion action experts across morphologies with a three stage curriculum,BC ,Self collecting,LIBERO
RoboCat,2023,https://arxiv.org/pdf/2306.11706,https://github.com/kyegomez/RoboCAT,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain on heterogeneous multi robot data and update on real trajectories,BC ,ImageNet;DeepMind Control Suite,RGB Stacking Benchmark
Dita,2024,https://arxiv.org/pdf/2503.19757,https://robodita.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Use OXE dataset and diffusion Transformers to learn cross environment behaviors,BC ,OXE; Droid,SimplerEnv
EO-1,2025,https://arxiv.org/pdf/2508.21112,https://github.com/eo-robotics/EO1,Generalization and Adaptation for Continuous Learning,Open-World Generalization, Pretrain a shared backbone on 1.5M EO Data,BC,LLaVA-1.5;LLaVA-Video-178K;PixMo-Points,RoboVQA
R3M,2022,https://arxiv.org/pdf/2203.12601,https://sites.google.com/view/robot-r3m/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain visual encoders on massive human first-person videos,Predictive Modeling,Ego4D,Franka Kitchen
Ego4D,2022,https://arxiv.org/pdf/2110.07058,https://ego4d-data.org/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain visual encoders on massive human first-person videos,Predictive Modeling,Ego4D,Episodic Memory
GR-1,2023,https://arxiv.org/pdf/2312.13139,https://gr1-manipulation.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain on massive human egocentric video datasets,Predictive Modeling,Ego4D,CALVIN
Gr-2,2024,https://arxiv.org/pdf/2410.06158,https://gr2-manipulation.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pretrain on massive human egocentric video datasets,Predictive Modeling,HowTo100M; Ego4D; Something-Something V2,CALVIN;Real-World Evaluation
ICIL,2024,https://arxiv.org/pdf/2408.15980,https://icrt.dev/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages in-context learning to infer tasks from few-shot demonstrations without retraining,BC and Predictive Modeling,DROID,ICIL
TRA,2025,https://arxiv.org/pdf/2502.05454,https://tra-paper.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Use temporal contrastive loss to structure representation space,BC and Predictive Modeling and RL,Bridge Data,Real-World Evaluation 
ObjectVLA,2025,"""https://arxiv.org/pdf/2502.19250",https://objectvla.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Jointly train on robot trajectories and box labeled VL corpora,BC ,ObjectVLA-Demo,ObjectVLA-Bench
LERF,2023,https://arxiv.org/pdf/2303.09553,https://www.lerf.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Fuse CLIP with 3D NeRFs,BC,LERF-Demo,LERF-Bench
RUM,2025,https://arxiv.org/pdf/2508.12922,https://github.com/kairanzhao/RUM,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Pair large scale home demonstrations with multimodal LLM reasoning,BC and Predictive Modeling,-,-
Align-Then-Steer,2025,https://arxiv.org/pdf/2509.02055,https://github.com/TeleHuman/Align-Then-Steer,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages a latent-space adapter to steer a frozen VLA model non-invasively,BC and Predictive Modeling,DROID; Kuka; ALOHA,RoboTwin
CACTI,2022,https://arxiv.org/pdf/2212.05711,https://cacti-framework.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages Stable Diffusion for zero-shot inpainting to diversify expert images without extra rollouts,BC and Predictive Modeling,CACTI-Sim-100,CACTI-Sim-100
GenAug,2023,https://arxiv.org/pdf/2302.06671,https://genaug.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages text-to-image synthesis from few-shot demos and prompts to generate diverse consistent scenes,BC ,Self-built Data,-
ROSIE,2023,https://arxiv.org/pdf/2302.11550,https://diffusion-rosie.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Distill internet scale VLM knowledge into robot training,BC and Predictive Modeling,RT-1; Self collecting,ROSIE
LMM-3DP,2025,https://arxiv.org/pdf/2501.18733,https://lmm-3dp-release.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages a high-level planner for abstract knowledge and a low-level executor for reusable skills,BC,Self-built Data,Real-Robot Evaluation
BAKU,2024,https://arxiv.org/pdf/2406.07539,https://baku-robot.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages dynamic multimodal sensor fusion,BC ,LIBERO-90; MetaWorld; DeepMind Control Suite,LIBERO-90;MetaWorld
StructDiffusion,2022,https://arxiv.org/pdf/2211.04604,https://structdiffusion.github.io/,Generalization and Adaptation for Continuous Learning,Open-World Generalization,Leverages language guided diffusion to generate multiple action structures,Predictive Modeling,-,Google Scanned Objects with Pybullet
Think Small Act Big,2025,https://arxiv.org/pdf/2504.00420,-,Generalization and Adaptation for Continuous Learning,Continual Learning and Incremental Skill Acquisition,Leverages new prompts or codebook entries to add skills without modifying existing components,BC,MimicGen,LIBERO
SPECI,2025,https://arxiv.org/pdf/2504.15561,-,Generalization and Adaptation for Continuous Learning,Continual Learning and Incremental Skill Acquisition,Leverages new prompts or codebook entries to add skills without modifying existing components,BC,LIBERO,LIBERO
InstructVLA,2025,https://arxiv.org/pdf/2507.17520,https://yangs03.github.io/InstructVLA_Home/,Generalization and Adaptation for Continuous Learning,Continual Learning and Incremental Skill Acquisition,Leverages a two-stage paradigm with a MoE to route between reasoning and action modules,BC and Predictive Modeling,Bridge Data;Fractal;RT-1;RT-1-X,VLMEvalKit
iManip,2025,https://arxiv.org/pdf/2503.07087,https://github.com/Ghy0501/Awesome-Continuall-Learning-in-Generative-Models,Generalization and Adaptation for Continuous Learning,Continual Learning and Incremental Skill Acquisition,Add skill specific weights while freezing old ones,BC ,RLBench,RLBench
ExpReSVLA,2025,https://arxiv.org/pdf/2511.06202,-,Generalization and Adaptation for Continuous Learning,Continual Learning and Incremental Skill Acquisition,Use Compressed Experience Replay,BC,OpenVLA pretraining dataset,LIBERO
SLIM,2025,https://arxiv.org/pdf/2410.09615,https://github.com/Paramathic/slim,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Compress RGB into segmentation and depth maps,BC and Predictive Modeling,C4,MMLU;PIQA
MaiSkill3,2024,https://arxiv.org/pdf/2410.00425,https://github.com/haosulab/ManiSkill,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Leverages GPU-parallel rendering domain randomization and background composition,BC,ManiSkill3,ManiSkill3
GenAug,2023,https://arxiv.org/abs/2302.06671,https://github.com/genaug/genaug,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Leverages  web scale image generative models to synthesize images from few demonstrations,,10 real world table,real world evaluation
DreamGen,2025,https://arxiv.org/pdf/2505.12705,https://github.com/nvidia/GR00T-dreams,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Train a world model on massive real world data,Predictive Modeling and RL,GR1 humanoid teleoperation pick-and-place; RoboCasa; DROID,RoboCasa
RynnVLA-001,2025,https://arxiv.org/pdf/2509.15212,https://github.com/alibaba-damo-academy/RynnVLA-001,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Pretrain large scale video generation with human centric trajectory modeling,BC and Predictive Modeling,Self collecting ego-centric human manipu-demo; EgoDex,CALVIN
RIDG,2024,https://arxiv.org/pdf/2412.09858,https://generalist-distillation.github.io/,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Train specialist RL policies then distill trajectories into VLA,RL ,Generating by RL,Connector Insertion
Refined Policy Distillation,2025,https://arxiv.org/pdf/2503.05833,https://refined-policy-distillation.github.io/,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Add MSE constraint to guide RL agent,RL ,ManiSkill3,ManiSkill3
iRe-VLA,2025,https://arxiv.org/pdf/2501.16664,https://github.com/HaochenZ11/IRef-VLA,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Freeze backbone and train lightweight action head in alternating phases,RL ,MetaWorld,MetaWorld
CO-RFT,2025,https://arxiv.org/pdf/2508.02219,https://github.com/cccedric/conrft,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning, designs a chunked temporal difference learning mechanism that feeds entire action sequences into the critic to predict multi step returns ,RL ,CO-RFT,CO-RFT
VLM-RMs,2023,https://arxiv.org/pdf/2310.12921,https://github.com/AlignmentResearch/vlmrm,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Infer rewards via perceptual alignment in shared embedding space,Predictive Modeling and RL,-,CartPole;MountainCar
RoboCLIP,2023,https://arxiv.org/pdf/2310.07899,https://sites.google.com/view/roboclip/home,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Leverages video trajectories by computing video language similarity for sparse rewards ,BC and Predictive Modeling,HowTo100M,MetaWorld;Franka Kitchen
Affordance-Guided RL,2024,https://arxiv.org/pdf/2407.10341,https://sites.google.com/view/affordance-guided-rl,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Convert VLM predicted grasp points and trajectories into dense rewards,BC and Predictive Modeling,Bridge Data,PyBullet Bin-Sorting Cloth Covering
RL VLM-F,2024,https://arxiv.org/pdf/2402.03681,https://rlvlmf2024.github.io/,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Leverages GPT-4V to infer preference-based rewards from observation pairs without human labels,BC ,-,OpenAI Gym CartPole
GRAPE,2024,https://arxiv.org/pdf/2411.19309,https://grape-vla.github.io/,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Leverages VLMs to decompose tasks and generate stage-wise preferences for multi-objective rewards,Predictive Modeling and RL,Real-world SFT dataset; Simpler-Env SFT;  LIBERO,Real-world 30 tasks
Eureka,2023,https://arxiv.org/pdf/2310.12931,https://eureka-research.github.io/,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning, Prompt LLM with environment code and task specs to generate rewards,RL ,-,Isaac Gym
VIP,2023,https://arxiv.org/pdf/2210.00030,https://sites.google.com/view/vip-rl,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Perform implicit value optimization from video,,Ego4D,Franka Kitchen
VLA-RL,2025,https://arxiv.org/pdf/2505.18719,https://github.com/GuanxingLu/vlarl,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Finetune VLM into a structured process reward model,Predictive Modeling and RL,Dataset of OpenVLA; LIBERO,LIBERO
AutoRT,2025,https://arxiv.org/pdf/2401.12963,https://auto-rt.github.io/,Security Interpretability and Reliable Interaction,Reliability and Safety Assurance,Leverages structured prompting to encode multi level constraints,BC,AutoRT,AutoRT
SafeVLA,2025,https://arxiv.org/pdf/2503.03480,https://pku-safevla.github.io/,Security Interpretability and Reliable Interaction,Reliability and Safety Assurance,Leverages a cost function in a constrained MDP to model physically hazardous behaviors,RL ,CHORES,Safety-CHORES
Genimi Robotics,2025,https://arxiv.org/pdf/2503.20020,https://github.com/google-deepmind/gemini-robotics-sdk,Security Interpretability and Reliable Interaction,Reliability and Safety Assurance,Leverages Constitutional AI post-training on safety data to enforce human-centric principles,BC and Predictive Modeling and RL,ALOHA 2;Embodied Reasoning;VQA,ERQA
GPI,2025,https://arxiv.org/pdf/2508.11960,-,Security Interpretability and Reliable Interaction,Reliability and Safety Assurance,Leverages confidence estimation probabilistic action generation and language guided backtracking to replan under uncertainty,Predictive Modeling and RL,-,VIMA-Bench;Ravens
RationalVLA,2025,https://arxiv.org/pdf/2506.10826,https://irpn-eai.github.io/RationalVLA/,Security Interpretability and Reliable Interaction,Reliability and Safety Assurance,Uses a learnable refusal token to reject unsafe or invalid commands,BC and Predictive Modeling and RL,CALVIN A/B/C splits + RAMA,CALVIN ABC
Diffusion-VLA,2024,https://arxiv.org/pdf/2412.03293,https://diffusion-vla.github.io/,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Condition diffusion policy on natural language reasoning,Predictive Modeling and RL,Droid;OXE,Real-World Multi-Task Learning
ECoT,2024,https://arxiv.org/pdf/2407.08693,https://embodied-cot.github.io/,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction, Leverages editable step-by-step rationales that users can correct via language,BC,Bridge Data;RT-2-X,ECoT
CoT-VLA,2025,https://arxiv.org/pdf/2503.22020,https://cot-vla.github.io/,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Adds visual subgoal images to render intermediate plans observable,BC and Predictive Modeling,Jaco Play;Berkeley Autolab UR5;Berkeley Fanuc Manipulation,LIBERO
RT-H,2024,https://arxiv.org/pdf/2403.01823,https://rt-hierarchy.github.io/,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Leverages separated language-action generation to enable self-explanation and language-level intervention,BC,Kitchen,RT-H
CrayonRobo,2025,https://arxiv.org/pdf/2505.02166,-,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Uses structured semantically explicit visual prompts to externalize decision logic into a shared and interpretable language,BC,SAPIEN + PartNet-Mobility,CrayonRobo
SwitchVLA,2025,https://arxiv.org/pdf/2506.03574,https://switchvla.github.io/,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Use structured task switching with rollback of conflicting actions,BC and Predictive Modeling,LIBERO-Goal,LIBERO-Goal
Hi Robot,2025,https://arxiv.org/pdf/2502.19417,https://www.pi.website/research/hirobot,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Outputs readable low-level commands from a high-level planner ,BC,Teleoperated robot demonstrations;D_syn,Hi Robot
GraSPVLA,2025,https://arxiv.org/pdf/2511.04357,https://github.com/PKU-EPIC/GraspVLA,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Uses symbolic state conversion of visual inputs for planning in a symbolic space,BC and Predictive Modeling,Bridge Data; RT-X,DAHLIA
DIARC-OpenVLA,2025,https://arxiv.org/pdf/2502.04558v1,-,Security Interpretability and Reliable Interaction,Interpretability and Trustworthy Interaction,Train linear probes to map hidden activations to symbolic states for transparent monitoring,BC and Predictive Modeling and RL,Dataset of OpenVLA,LIBERO-spatial
Moto,2025,https://arxiv.org/pdf/2401.03306,https://github.com/linhlpv/awesome-offline-to-online-RL-papers,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Uses unsupervised or self-supervised learning to acquire task-centric latent action representations from videos,,MetaWorld; Franka Kitchen,MetaWorld
LAPA,2024,https://arxiv.org/pdf/2410.11758,https://latentactionpretraining.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Uses unsupervised or self-supervised learning to acquire task-centric latent action representations from videos,BC and RL,Language Table; OXE;Something-Something V2,WidowX 7DOF
UniVLA,2025,https://arxiv.org/pdf/2505.06111,https://github.com/OpenDriveLab/UniVLA,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Uses unsupervised or self-supervised learning to acquire task-centric latent action representations from videos,BC,OXE; Ego4D; Bridge Data,CALVIN
RDT-1B,2024,https://arxiv.org/pdf/2410.07864,https://rdt-robotics.github.io/rdt-robotics/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Map diverse robot actions into unified physical or latent semantic vectors,BC,RT-1;DROID;RH20T,RDT-1B
AgiBot,2025,https://arxiv.org/pdf/2503.06669,https://opendrivelab.com/AgiBot-World/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Map diverse robot actions into unified physical or latent semantic vectors,BC and Predictive Modeling,AgiBot Dataset;OXE,AgiBot
Cross-Embodied Learning,2024,https://arxiv.org/pdf/2408.11812,https://crossformer-model.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Tokenize visual and proprioceptive inputs for a shared Transformer,BC and RL,DROID;ALOHA-multi-task;GNM,WidowX Manipulation
RT-1,2022,https://arxiv.org/pdf/2212.06817,https://robotics-transformer1.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Use unified tokenization semantic alignment or self supervised learning for VLA grounding,BC ,RT-1,RT-1
ViSA-Flow,2025,https://arxiv.org/pdf/2505.01288,https://visaflow-web.github.io/ViSAFLOW/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Use unified tokenization semantic alignment or self supervised learning for VLA grounding,BC and Predictive Modeling,AMASS; HumanML3D; Motion-X,CALVIN ABC
Humanoid-VLA,2025,https://arxiv.org/pdf/2502.14795,https://github.com/AllenXuuu/HumanVLA,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Use unified tokenization semantic alignment or self supervised learning for VLA grounding,BC and RL,Bridge Data; RT-X,T2M
EgoVLA,2025,https://arxiv.org/pdf/2507.12440,https://rchalyang.github.io/EgoVLA/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Use MANO hand models and inverse kinematics,BC and Predictive Modeling,Ego-Centric Human Manipulation Dataset,Ego Humanoid Manipulation Benchmark
Dexwild,2025,https://arxiv.org/pdf/2505.07813,https://dexwild.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Use MANO hand models and inverse kinematics,BC and Predictive Modeling,DexWild-System human demo ,Dexwild
CACTI,2022,https://arxiv.org/pdf/2212.05711,https://cacti-framework.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,augment robot data via inpainting or restyling,BC,CACTI,CACTI
GenAug,2023,https://arxiv.org/pdf/2302.06671,https://genaug.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,augment robot data via inpainting or restyling,BC and Predictive Modeling,GenAug,GenAug
ROSIE,2023,https://arxiv.org/pdf/2302.11550,https://diffusion-rosie.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,provides semantic-level enrichment using VLM priors,BC and Predictive Modeling,RT-1,ROSIE
Re-Mix,2024,https://arxiv.org/pdf/2408.14037,https://github.com/jhejna/remix,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Adjust sampling weights of heterogeneous data subsets via performance feedback,BC,Bridge Data;OXE; RoboMimic NutAssemblySquare,RoboMimic NutAssemblySquare
RH20T,2023,https://arxiv.org/pdf/2307.00595,https://rh20t.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Enforce strict temporal alignment across sensors,BC and Predictive Modeling,RH20T,RH20T
BridgeData v2,2023,https://arxiv.org/pdf/2308.12952,https://rail-berkeley.github.io/bridgedata/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,integrates diverse data types into a standardized format,BC and Predictive Modeling,Bridge Data,Bridge Data
RoboCasa,2024,https://arxiv.org/pdf/2406.02523,https://robocasa.ai/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Provide large scale high fidelity digital environments,BC and Predictive Modeling and RL,RoboCasa,RoboCasa
CoVLA,2025,https://arxiv.org/pdf/2408.10845,https://turingmotors.github.io/covla-ad/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Provide large scale high fidelity digital environments,BC and Predictive Modeling and RL,CoVLA,CoVLA
Ego4D,2022,https://openaccess.thecvf.com/content/CVPR2022/papers/Grauman_Ego4D_Around_the_World_in_3000_Hours_of_Egocentric_Video_CVPR_2022_paper.pdf,https://ego4d-data.org/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,teaching robots to operate in human environments,BC and Predictive Modeling and RL,Ego4D,Ego4D
EPIC-KITCHENS,2020,https://arxiv.org/pdf/2005.00343,https://epic-kitchens.github.io/2025,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,teaching robots to operate in human environments,BC and Predictive Modeling,EPIC-KITCHENS,EPIC-KITCHENS
Ego-Exo4D,2024,https://arxiv.org/pdf/2311.18259,https://ego-exo4d-data.org/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Fuse first person and third person perspectives,BC and Predictive Modeling and RL,Ego-Exo4D,Ego-Exo4D
RoboMM,2024,https://arxiv.org/pdf/2412.07215,https://github.com/EmbodiedAI-RoboTron/RoboTron-Mani,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Use three level semantic alignment for joint training,BC and Predictive Modeling,RoboData,CALVIN;MetaWorld
OXE,2023,https://arxiv.org/pdf/2310.08864,https://robotics-transformer-x.github.io/,Dataset Construction and Benchmarking Standards,Multi-Source Heterogeneous Data,Aggregate multiple datasets into a single benchmark,BC and Predictive Modeling,OXE,OXE
RLBench,2025,https://arxiv.org/pdf/1909.12271,https://github.com/stepjam/RLBench,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,-,BC and Predictive Modeling and RL,RLBench,RLBench
RoboMimic,2021,https://arxiv.org/pdf/2108.03298,https://github.com/ARISE-Initiative/robomimic,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Uses human demonstration data to evaluate offline learning methods and identify challenges in leveraging human-generated data,-,Machine-Generated (MG);Proficient-Human (PH);Multi-Human (MH),RoboMimic
EUQ,2025,https://arxiv.org/pdf/2502.13105v2,-,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Uses a human-assessed multidimensional scoring system to capture process quality beyond binary success,-,-,-
ManiSkills,2024,https://arxiv.org/pdf/2410.00425,https://github.com/haosulab/ManiSkill,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Contributes standardized APIs and task suites,BC and Predictive Modeling and RL,ManiSkill3,ManiSkill3
robosuits,2020,https://arxiv.org/pdf/2009.12293,https://github.com/ARISE-Initiative/robosuite,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Contributes standardized APIs and task suites,BC and Predictive Modeling and RL,-,RoboSuite
CALVIN,2022,https://arxiv.org/pdf/2112.03227,https://github.com/mees/calvin,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,require the execution of long sequences of language-guided operations,BC and Predictive Modeling and RL,CALVIN,CALVIN
LIBERO,2023,https://arxiv.org/pdf/2306.03310,https://libero-project.github.io/intro.html,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Introduces the first lifelong-robotics benchmark with standardized metrics,BC and Predictive Modeling and RL,LIBERO,LIBERO
Ego-Exo4D,2024,https://arxiv.org/pdf/2311.18259,https://ego-exo4d-data.org/,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Introdues synchronized first-third-person recordings,BC and Predictive Modeling and RL,Ego-Exo4D,Ego-Exo4D
From Intention to Execution,2025,https://arxiv.org/pdf/2506.09930,https://ai4ce.github.io/INT-ACT/,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Uses intention-execution gap probing to cover object diversity linguistic complexity and visual-language reasoning,BC and Predictive Modeling and RL,Bridge Data,INT-ACT
InstructVLA,2025,https://arxiv.org/pdf/2507.17520,https://yangs03.github.io/InstructVLA_Home/,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Releases SimplerEnv-Instruct with 80 zero-shot tasks,BC and Predictive Modeling,Bridge Data;OXE;RT-1;RT-2,SimplerEnv;SimplerEnv-Instruct
Benchmarking VLAs,2024,https://arxiv.org/pdf/2411.05821,https://multinet.ai/static/pages/Multinetv01.html,Dataset Construction and Benchmarking Standards,Evaluation and Benchmark,Uses unified IO metrics and multi robot coverage as a blueprint shifting focus from tasks to metrics,BC,OXE,OXE
ProphRL, 2025-11-25, https://arxiv.org/pdf/2511.20633, https://LogosRoboticsGroup.github.io/ProphRL,Generalization and Adaptation for Continuous Learning,Online Interaction and Reinforcement Learning,Pretrain a unified action-conditioned world model (Prophet) on diverse robot data,BC and Predictive Modeling and RL, AgiBot;DROID;OXE;LIBERO,LIBERO;SimplerEnv-WidowX;BRIDGE
DiG-Flow, 2025-12-1, https://arxiv.org/pdf/2512.01715, https://beingbeyond.github.io/DiG-Flow,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Compute a distributional discrepancy between observation and action embeddings to guide residual feature updates for robust flow matching,Predictive Modeling,LIBERO;RoboCasa,LIBERO;RoboCasa
RAGNet, 2025-7-31, https://arxiv.org/pdf/2507.23734, https://github.com/Dexmal-AI/RAGNet, Dataset Construction and Benchmarking Standards, Evaluation and Benchmark, construct a large-scale reasoning-based affordance segmentation dataset and propose AffordanceNet for open-world grasping, -, HANDAL;OXE;EgoObjects;GraspNet, HANDAL;GraspNet Novel;3DOI;RLBench
VLA-4D, 2025-11-21, https://arxiv.org/pdf/2511.17199, -, Multi-Modal Fusion and Physical World Representation, From 2D Images to SPatial Temporal Representations, Embed 3D positions and 1D time into visual features and extend actions with temporal variables for coherent manipulation, Predictive Modeling, Scan2Cap;ScanQA;ScanRef;LIBERO, LIBERO
LatBot, 2025-11-28, https://arxiv.org/pdf/2511.23034, https://mm-robot.github.io/distill_latent_action, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Learn instruction-guided latent actions from multi-frame videos and jointly decode future frames and inter-frame actions, BC and Predictive Modeling, OXE;AgiBot;EgoDex;DROID, SIMPLER;LIBERO;Franka real-robot tasks
DeepThinkVLA, 2025-10-31, https://arxiv.org/pdf/2511.15669, https://github.com/wadeKeith/DeepThinkVLA, From Complex Instructions to Robust and Real-Time Execution, Real-Time Execution and Computing Efficiency, Use a hybrid-attention decoder with SFT then outcome-based RL to align reasoning with actions, BC and RL, LIBERO demonstrations;embodied CoT dataset, LIBERO
Mantis, 2025-11-20, https://arxiv.org/pdf/2511.16175, https://github.com/zhijie-group/Mantis, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Disentangle visual foresight from action learning using a diffusion transformer head with latent action queries and progressive multimodal training, BC and Predictive Modeling, Something-Something V2;DROID;LLaVA-Instruct and 38 multimodal datasets, LIBERO
X-VLA, 2025-10-11, https://arxiv.org/pdf/2510.10274, https://thu-air-dream.github.io/X-VLA/, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Learn embodiment-specific soft prompts to absorb cross-embodiment heterogeneity and enable scalable pretraining and efficient adaptation, BC and Predictive Modeling, AGIBOT-beta;Droid;RoboMind;Soft-FOLD, LIBERO;Simpler-WidowX;Calvin;RoboTwin-2.0;VLABench
MergeVLA, 2025-11-24, https://arxiv.org/pdf/2511.18810, https://mergevla.github.io, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Introduce sparsely activated LoRA masks and cross-attention-only action experts with a training-free task router to enable mergeable multi-skill VLA policies, BC, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robot, LIBERO;LIBERO-Plus;RoboTwin 2.0;SO-101 real robo
GigaWorld-0, 2025-11-30, https://arxiv.org/pdf/2511.19861, https://giga-world-0.github.io, Multi-Modal Fusion and Physical World Representation, Dynamic and Predictive World Models, Unify video generation and 3D physics-aware reconstruction to synthesize controllable embodied interaction data, BC and Predictive Modeling and RL, AgiBot World;RoboMind;proprietary in-house robotic platforms, PBench Robot Set;DreamGen Bench
HiMoE-VLA, 2025-12-05, https://arxiv.org/pdf/2512.05693, https://github.com/ZhiyingDu/HiMoE-VLA, Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution;Multi-Modal Fusion and Physical World Representation, Open-World Generalization;Real-Time Execution and Computing Efficiency;Dynamic and Predictive World Models, Use a hierarchical mixture of experts with action space and heterogeneity balancing experts to enable cross domain transfer;Cache intermediate VLM key value pairs for faster inference without degrading performance;Train actions with flow matching to model multimodal action distributions, BC and Predictive Modeling, OXE;ALOHA, CALVIN;LIBERO
HiF-VLA, 2025-12-10, https://arxiv.org/pdf/2512.09928, https://hifvla.github.io, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution, From 2D Images to SPatial Temporal Representations;Real-Time Execution and Computing Efficiency, Leverage low-dimensional motion vectors for hindsight foresight and action fusion in a unified latent space;Use compact motion representations to expand temporal reasoning with negligible latency, BC and Predictive Modeling, OXE;LIBERO, LIBERO-Long;CALVIN ABC
Lumo-1, 2025-12-10, https://arxiv.org/pdf/2512.08580, https://www.astribot.com/research/Lumo1, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution;Generalization and Adaptation for Continuous Learning;Security Interpretability and Reliable Interaction;Dataset Construction and Benchmarking Standards, From 2D Images to SPatial Temporal Representations;Hierarchical Planning and Task Decomposition;Online Interaction and Reinforcement Learning;Interpretability and Trustworthy Interaction;Multi-Source Heterogeneous Data;Evaluation and Benchmark, Build a vision language action model with spatial action tokenization and structured reasoning;Train with staged reasoning action alignment and flow matched action expert for efficient execution;Leverage cross embodiment co training and RL to improve generalization;Provide explicit reasoning traces for transparent decisions;Curate large scale multi source VLM and robot data and define evaluation suites, BC and Predictive Modeling and RL, Cambrian-10M;LLaVA-665K;Pixmo Caption;Robo2VLM, BLINK;CV-Bench;EmbSpatial;RefSpatial-Bench;SAT;Where2Place;RoboSpatial
GLaD, 2025-12-10, https://arxiv.org/pdf/2512.09619, -, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning, From 2D Images to SPatial Temporal Representations;Open-World Generalization, Distill geometric features from a frozen VGGT teacher into LLM hidden states for visual tokens to fuse 3D priors;Pretrain on Bridge then fine tune with LoRA for robust policy generalization, BC, Bridge Data, LIBERO;LIBERO-PRO
ViFailback, 2025-12-03, https://arxiv.org/pdf/2512.02787, https://x1nyuzhou.github.io/vifailback.github.io, Dataset Construction and Benchmarking Standards;From Complex Instructions to Robust and Real-Time Execution;Security Interpretability and Reliable Interaction, Evaluation and Benchmark;Error Detection and Autonomous Recovery;Interpretability and Trustworthy Interaction, Build a large real-world failure VQA dataset and benchmark for diagnosis and correction;Use a VLM to detect localize and classify failures then generate textual and visual corrective guidance;Use explicit on-frame visual symbols to provide interpretable corrective cues, -, ViFailback dataset, ViFailback-Bench Lite;ViFailback-Bench Hard
RoboWheel, 2025-12-02, https://arxiv.org/pdf/2512.02729, https://zhangyuhong01.github.io/Robowheel, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Sim-to-real Gap in Deployment, Converts human hand-object interaction videos from diverse sources into training-ready supervision via a physics-aware reconstruction pipeline;Uses a simulation-augmented data flywheel with domain randomization in Isaac Sim to enrich trajectory distributions for robust real-world transfer, BC and RL, HORA;DexYCB;OakInk, Real-World-Tasks;OakInk
BayesVLA, 2025-12-12, https://arxiv.org/pdf/2512.11218, https://xukechun.github.io/papers/BayesVLA, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Decompose policy into vision-action prior and language-conditioned likelihood to mitigate modality imbalance, BC, DROID;LIBERO, LIBERO;LIBERO-PRO
Motus, 2025-12-15, https://arxiv.org/pdf/2512.13030, https://motus-robotics.github.io/motus, Multi-Modal Fusion and Physical World Representation;Dataset Construction and Benchmarking Standards, Dynamic and Predictive World Models;Multi-Source Heterogeneous Data, Integrates video generation and action experts via Mixture-of-Transformer architecture with a UniDiffuser-style scheduler;Introduces latent actions derived from optical flow to unify large-scale heterogeneous data across embodiments, BC and Predictive Modeling, RoboTwin;LIBERO;VLAbench;AC-One Data;Agilex-Aloha-2 Data, RoboTwin;LIBERO-Long;VLAbench
VLSA-AEGIS, 2025-12-09, https://arxiv.org/pdf/2512.11891, https://vlsa-aegis.github.io/, Security Interpretability and Reliable Interaction;Dataset Construction and Benchmarking Standards, Reliability and Safety Assurance;Evaluation and Benchmark, Introduce a plug-and-play safety constraint layer formulated via control barrier functions into VLA models;Construct a comprehensive safety-critical benchmark SafeLIBERO spanning distinct manipulation scenarios with varying complexities, -, -, SafeLIBERO
OXE-AugE, 2025-12-15, https://arxiv.org/pdf/2512.13100, https://OXE-AugE.github.io/, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Open-World Generalization, Augments existing datasets with diverse robot embodiments using a scalable pipeline combining simulation rendering and learned masks;Fine-tunes generalist policies on augmented data to improve zero-shot transfer to unseen embodiments, BC, OXE;OXE-AugE;Bridge Data, Robosuite;Bridge Data
DexGrasp-VLA,2025-12-13,https://arxiv.org/pdf/2511.00139,https://dexvla-seed.github.io/dex-vla, Dataset Construction and Benchmarking Standards;Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning,Multi-Source Heterogeneous Data;The GAP between Semantics Perception and Physical Interaction;Continual Learning and Incremental Skill Acquisition,Propose a Shared Autonomy framework that partitions control along macro-micro motion domains for efficient data collection;Develop an Arm-Hand Feature Enhancement module to explicitly capture distinct latent features of arm and hand movements;Implement a Corrective Human-in-the-loop Teleoperation system to enable continuous policy improvement via failure recovery,BC and Predictive Modeling,LSTM Pretraining Dataset;DexGrasp-VLA Hand Policy Dataset;End-to-End Arm-Hand VLA Dataset;Corrective Intervention Datasets,Real-world-Tasks;Long-horizon manipulation tasks;Industrial peg-in-hole assembly
VL-JEPA, 2025-12-11,https://arxiv.org/pdf/2512.10942,-,Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution,Dynamic and Predictive World Models;Real-Time Execution and Computing Efficiency,Predict continuous embeddings of target texts in an abstract representation space using a joint embedding predictive architecture;Enable selective decoding by invoking the text decoder only when significant semantic changes are detected in the predicted embedding stream,Predictive Modeling,Datacomp;YFCC-100M;Ego4D;HowTo100M;PLM-Image-Auto;PLM-Video-Auto,Something-Something V2;EgoExo4D;Kinetics-400;MSR-VTT;ActivityNet;YouCook2;GQA;TallyQA;POPE;WorldPrediction-WM
Human to Robot, 2025-12-16, https://www.physicalintelligence.company/download/human_to_robot.pdf, https://www.physicalintelligence.company/research/human_to_robot, Generalization and Adaptation for Continuous Learning, Open-World Generalization, Co-train human videos as an additional embodiment with robot data using unified trajectory and sub-task prediction objectives, BC and Predictive Modeling, Human Video Data;Robot Teleoperation Data, Bussing;Spice;Dresser;Sort Eggs
GR00T N1, 2025-03-28, https://arxiv.org/pdf/2503.14734, https://research.nvidia.com/labs/gear/gr00t-n1_6/, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Multi-Source Heterogeneous Data;Open-World Generalization, Structure training corpora as a data pyramid unifying human videos synthetic data and real robot trajectories using latent and pseudo actions;Employ a dual-system architecture integrating a vision-language backbone with a flow-matching diffusion policy for cross-embodiment control, BC, GR00T N1 Humanoid Pre-Training Dataset;OXE;AgiBot-Alpha;RoboCasa;DexMimicGen;Ego4D;Ego-Exo4D;Assembly-101;EPIC-KITCHENS;HOI4D;HoloAssist;RH20T-Human, RoboCasa;DexMimicGen;GR-1 Tabletop;GR-1 Humanoid Real-World Tasks
WholeBodyVLA,2025-12-15, https://arxiv.org/pdf/2512.11047,https://opendrivelab.com/WholeBodyVLA,Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution,Open-World Generalization;Real-Time Execution and Computing Efficiency,Train separate locomotion and manipulation latent action models on human videos to supervise VLA training;Employ a discrete command interface with two-stage curriculum RL policy for precise execution,BC and Predictive Modeling and RL,Human egocentric videos;Agibot World;Collected teleoperation trajectories,Real-World Tasks
VideoVLA, 2025-12-07, https://arxiv.org/pdf/2512.06963, https://videovla-nips2025.github.io/, Generalization and Adaptation for Continuous Learning;Multi-Modal Fusion and Physical World Representation, Open-World Generalization;Dynamic and Predictive World Models, Leverage pre-trained video generation models and a dual-prediction strategy to transfer physical knowledge to robotic manipulation;Jointly denoise video latents and action vectors within a unified multi-modal diffusion transformer architecture, BC and Predictive Modeling, OXE, SIMPLER
MoE-DP, 2025-11-07, https://arxiv.org/pdf/2511.05007, https://moe-dp-website.github.io/MoE-DP-Website/, From Complex Instructions to Robust and Real-Time Execution;Security Interpretability and Reliable Interaction, Hierarchical Planning and Task Decomposition;Error Detection and Autonomous Recovery;Interpretability and Trustworthy Interaction, Integrate a Mixture of Experts layer to decompose long-horizon tasks into specialized skills within the diffusion policy;Leverage dynamic expert routing to detect failures and reactivate appropriate experts for subtask retries;Apply auxiliary load balancing and entropy losses to enforce distinct mappings between experts and semantic task phases, BC, Self-built Data, Custom MimicGen-inspired suite;Real-world manipulation suite
MiVLA,2025-12-17, https://arxiv.org/pdf/2512.15411,-,Generalization and Adaptation for Continuous Learning,Sim-to-real Gap in Deployment,Utilizes kinematic rules with left/right hand coordinate systems for bidirectional alignment between human and robot action spaces,BC and Predictive Modeling,RoboTwin;Human Videos,RoboTwin-2.0
EVOLVE-VLA, 2025-12-16, https://arxiv.org/pdf/2512.14666, https://showlab.github.io/EVOLVE-VLA, Generalization and Adaptation for Continuous Learning, Online Interaction and Reinforcement Learning, Introduce accumulative progress estimation mechanism and progressive horizon extension strategy to tame noisy reward signals for test-time training, BC and RL, LIBERO, LIBERO
ManualVLA, 2025-12-01, https://arxiv.org/pdf/2512.02013, https://sites.google.com/view/maunalvla, From Complex Instructions to Robust and Real-Time Execution;Generalization and Adaptation for Continuous Learning, Hierarchical Planning and Task Decomposition;Sim-to-real Gap in Deployment, Design a unified Mixture-of-Transformers framework that selectively activates planning and action experts for coherent manual generation and execution;Construct a high-fidelity digital twin toolkit using 3D Gaussian Splatting to synthesize large-scale training data, BC and Predictive Modeling, OXE;DROID;RoboMind, RLBench
PolaRiS, 2025-12-18, https://arxiv.org/pdf/2512.16881, https://polaris-evals.github.io, Dataset Construction and Benchmarking Standards, Evaluation and Benchmark, Utilizes neural reconstruction methods to turn video scans into interactive simulation environments and develops a co-training recipe to bridge real-to-sim gaps, BC, DROID;PolaRiS Simulation Dataset;LIBERO, PolaRiS;RoboArena;LIBERO
ISS,2025-12-17, https://arxiv.org/pdf/2512.15020, -, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution,Dynamic and Predictive World Models;Real-Time Execution and Computing Efficiency,Introduces an implicit scene supervision module that predicts future point cloud features to enforce long-term geometric consistency;Uses a streamlined DiT architecture with sparse point cloud encoding to improve inference speed and training efficiency,BC and Predictive Modeling,Adroit;MetaWorld,Adroit;MetaWorld
GeoPredict, 2025-12-18, https://arxiv.org/pdf/2512.16811, https://jingjingqian75.github.io/GeoPredict-Page/, Multi-Modal Fusion and Physical World Representation, From 2D Images to SPatial Temporal Representations;Dynamic and Predictive World Models, Constructs a predictive 3D Gaussian geometry module to forecast workspace geometry with track guided refinement along future keypoint trajectories;Augments a continuous action policy with predictive kinematic priors that encode motion history and predict multi step 3D keypoint trajectories, BC and Predictive Modeling, RoboCasa;LIBERO, RoboCasa;LIBERO
AFI, 2025-12-08, https://arxiv.org/pdf/2512.07472, -, Generalization and Adaptation for Continuous Learning;From Complex Instructions to Robust and Real-Time Execution, Open-World Generalization;Error Detection and Autonomous Recovery, Employ 3D Spatial Affordance Fields to guide VLA behavior in out-of-distribution scenarios;Detect memory traps using proprioception and execute affordance-guided rollback for recovery, BC, Self-built Data;LIBERO, Real-world manipulation tasks;LIBERO-PRO
AdaWorld, 2025-06-02, https://arxiv.org/pdf/2503.18938, https://adaptable-world-model.github.io, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning, Dynamic and Predictive World Models;Open-World Generalization, Develops an autoregressive world model conditioned on latent actions extracted from videos in a self-supervised manner;Enables efficient adaptation and action transfer to novel environments by initializing the control interface with learned latent actions, Predictive Modeling, Gym Retro;Procgen;OXEt;Ego4D;Something-Something V2;MiraData, LIBERO;Something-Something V2;Habitat;Minecraft;DMLab;nuScenes;Procgen;VP2
PhysBrain, 2025-12-19, https://arxiv.org/pdf/2512.16793, https://zgc-embodyai.github.io/PhysBrain/, Dataset Construction and Benchmarking Standards;Multi-Modal Fusion and Physical World Representation, Multi-Source Heterogeneous Data;The GAP between Semantics Perception and Physical Interaction, Transform first-person videos into multi-level schema-driven VQA supervision with enforced evidence grounding and temporal consistency to construct the E2E-3M dataset;Train an egocentric-aware embodied brain on the E2E-3M dataset to bridge vision language models with physical intelligence and enable sample-efficient VLA fine-tuning, BC and Predictive Modeling, Ego4D;BuildAI;EgoDex;FineVision;Bridge;Fractal, EgoThink;SimplerEnv
MM-ACT⭐, 2025-12-08,  https://arxiv.org/pdf/2512.00975, https://github.com/HHYHRHY/MM-ACT, From Complex Instructions to Robust and Real-Time Execution;Multi-Modal Fusion and Physical World Representation, Real-Time Execution and Computing Efficiency;Hierarchical Planning and Task Decomposition, Adopts a one-step parallel decoding strategy for action generation to achieve low-latency inference;Integrates text image and action in shared token space to perform task planning and future image prediction under shared context, BC and Predictive Modeling, LIBERO;RoboTwin, LIBERO;RoboTwin;Franka Real-world
WALL-OSS⭐, 2025-09-08,  https://arxiv.org/pdf/2509.11766, https://x2robot.com/en/research/68bc2cde8497d7f238dde690, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution;Dataset Construction and Benchmarking Standards, The GAP between Semantics Perception and Physical Interaction;From 2D Images to SPatial Temporal Representations;Hierarchical Planning and Task Decomposition;Multi-Source Heterogeneous Data, Employ a tightly coupled Mixture-of-Experts architecture with static routing to align action and vision-language features;Leverage embodied VQA and discrete action priors to strengthen spatial reasoning and progress modeling;Develop Unified Cross-Level CoT to seamlessly unify instruction reasoning subgoal decomposition and fine-grained action synthesis;Aggregate over 10000 hours of data from self-collected robot trajectories open-source datasets and multimodal VQA with unified specifications, BC and Predictive Modeling, AgiBot World;Droid;Bc_z;RH20T;Furniture_bench;Fractal;Bridge Data v2, Embodied VQA Benchmark;Set-Table;Tidy-Bedroom;Place-by-Color;Block-Spell;Collect-Waste;Pick-Place-Cup
GENMANIP⭐, 2025-06-12,  https://arxiv.org/pdf/2506.10966, -, Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning, Evaluation and Benchmark;Open-World Generalization, Introduce a realistic tabletop simulation platform tailored for policy generalization studies with 200 human curated scenarios;Leverage LLM driven task oriented scene graph to synthesize diverse tasks using 10K annotated 3D object assets, BC, Objaverse;GRUtopia;PartNet-Mobility, GENMANIP-BENCH
ROBOGROUND⭐, 2025-04-30,  https://arxiv.org/pdf/2504.21530, https://robo-ground.github.io, Generalization and Adaptation for Continuous Learning;Dataset Construction and Benchmarking Standards, Open-World Generalization;Evaluation and Benchmark, Leverage grounding masks as effective intermediate representations to provide spatial guidance for policy networks;Design an automated pipeline to generate simulated manipulation data with diverse objects and instructions, BC, RoboCasa;Objaverse, RoboCasa
CronusVLA⭐, 2025-10-30,  https://arxiv.org/pdf/2506.19816, -, Multi-Modal Fusion and Physical World Representation;From Complex Instructions to Robust and Real-Time Execution, From 2D Images to SPatial Temporal Representations;Real-Time Execution and Computing Efficiency, Proposes a two-stage framework with single-frame pretraining and multi-frame post-training using feature chunking to aggregate temporal information;Optimizes inference speed by predicting learnable features and using a queue mechanism for feature caching, BC and Predictive Modeling, OXE;Bridge Data v2;Fractal;LIBERO, SimplerEnv;LIBERO;SimplerEnv-OR
InternVLA-M1⭐, 2025-10-15,  https://arxiv.org/pdf/2510.13778, https://internrobotics.github.io/internvla-m1.github.io/, Multi-Modal Fusion and Physical World Representation;Generalization and Adaptation for Continuous Learning;Dataset Construction and Benchmarking Standards, The GAP between Semantics Perception and Physical Interaction;Open-World Generalization;Multi-Source Heterogeneous Data, Employs a two-stage pipeline combining spatial grounding pre-training with spatially guided action post-training to bridge instructions and actions;Utilizes synthetic co-training and spatial prompting to achieve robust performance on unseen objects and long-horizon tasks;Builds a scalable simulation engine to generate large-scale diverse manipulation episodes and spatial grounding annotations, BC and Predictive Modeling, InternData-M1;RefCOCO;RoboRef It;OXE;LIBERO, SimplerEnv;LIBERO
X-VLA⭐,2025-10-14,https://arxiv.org/pdf/2510.10274,https://thu-air-dream.github.io/X-VLA/,Dataset Construction and Benchmarking Standards;Generalization and Adaptation for Continuous Learning,Multi-Source Heterogeneous Data;Open-World Generalization,Introduces distinct learnable soft prompt embeddings for each data source to absorb embodiment-specific variations;Employs a two-step adaptation process that warms up prompts before joint policy finetuning,BC and Predictive Modeling,Droid;RoboMind;AgiBot,LIBERO;Simpler;Calvin;RoboTwin-2.0;VLABench;NAVSIM